{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer, IterativeImputer, KNNImputer\n",
    "from deepctr.inputs import  SparseFeat, DenseFeat, get_feature_names\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import utils\n",
    "from deepctr.models import DeepFM\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"target\"] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train, test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['null'] = data.isna().sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse and replace value in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = [feat for feat in train.columns if feat not in ['id','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 values in nom_5, {'b3ad70fcb'} Replaced with nan\n",
      "4 values in nom_6, {'ee6983c6d', 'a885aacec', 'f0732a795', '3a121fefb'} Replaced with nan\n",
      "2 values in nom_9, {'1065f10dd', '3d19cd31d'} Replaced with nan\n"
     ]
    }
   ],
   "source": [
    "for col in sparse_features:\n",
    "    train_unique_values = set(train[col].dropna().unique())\n",
    "    test_unique_values  = set(test[col].dropna().unique())\n",
    "\n",
    "    symmetric_difference_values = train_unique_values.symmetric_difference(test_unique_values)\n",
    "    if symmetric_difference_values:\n",
    "        print(f'{len(symmetric_difference_values)} values in {col}, {symmetric_difference_values} Replaced with nan')\n",
    "        data.loc[data[col].isin(symmetric_difference_values), col] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_indicators = MissingIndicator(sparse=False).fit_transform(data[sparse_features]).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_indicator_cols = [feat+'_ind' for feat in sparse_features]\n",
    "for col in missing_indicator_cols:\n",
    "    data[col] = 0\n",
    "    data[col] = data[col].astype(np.uint8)\n",
    "data[missing_indicator_cols] = MissingIndicator(sparse=False).fit_transform(data[sparse_features]).astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat].fillna('-1',).astype(str).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data.target != -1].reset_index(drop=True)\n",
    "test  = data[data.target == -1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat, data[feat].nunique()) for feat in (sparse_features+missing_indicator_cols)]\n",
    "\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    def fallback_auc(y_true, y_pred):\n",
    "        try:\n",
    "            return roc_auc_score(y_true, y_pred)\n",
    "        except:\n",
    "            return 0.5\n",
    "    return tf.py_function(fallback_auc, (y_true, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicLR(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
    "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
    "        super(CyclicLR, self).__init__()\n",
    "\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "        if scale_fn == None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = lambda x: 1.\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = lambda x: 1 / (2. ** (x - 1))\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = lambda x: gamma ** (x)\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "        self.clr_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "        \n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
    "               new_step_size=None):\n",
    "        \"\"\"Resets cycle iterations.\n",
    "        Optional boundary/step size adjustment.\n",
    "        \"\"\"\n",
    "        if new_base_lr != None:\n",
    "            self.base_lr = new_base_lr\n",
    "        if new_max_lr != None:\n",
    "            self.max_lr = new_max_lr\n",
    "        if new_step_size != None:\n",
    "            self.step_size = new_step_size\n",
    "        self.clr_iterations = 0.\n",
    "\n",
    "    def clr(self):\n",
    "        cycle = np.floor(1 + self.clr_iterations / (2 * self.step_size))\n",
    "        x = np.abs(self.clr_iterations / self.step_size - 2 * cycle + 1)\n",
    "        if self.scale_mode == 'cycle':\n",
    "            return self.base_lr + (self.max_lr - self.base_lr) * np.maximum(0, (1 - x)) * self.scale_fn(cycle)\n",
    "        else:\n",
    "            return self.base_lr + (self.max_lr - self.base_lr) * np.maximum(0, (1 - x)) * self.scale_fn(\n",
    "                self.clr_iterations)\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.clr_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.clr())\n",
    "\n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "\n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "\n",
    "        K.set_value(self.model.optimizer.lr, self.clr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['target']\n",
    "N_Splits = 50\n",
    "Verbose = 1\n",
    "Epochs = 15\n",
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "radam = tfa.optimizers.RectifiedAdam(lr=0.0001,\n",
    "    total_steps=10000,\n",
    "    warmup_proportion=0.1,\n",
    "    min_lr=0.00001,)\n",
    "ranger = tfa.optimizers.Lookahead(radam, sync_period=6, slow_step_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:From /home/bf/anaconda3/envs/fastai2/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4726 - auc: 0.7048\n",
      "Epoch 00001: val_auc improved from -inf to 0.78420, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 131s 223us/sample - loss: 0.4726 - auc: 0.7049 - val_loss: 0.3982 - val_auc: 0.7842\n",
      "Epoch 2/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3993 - auc: 0.7839\n",
      "Epoch 00002: val_auc improved from 0.78420 to 0.78479, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 108s 184us/sample - loss: 0.3993 - auc: 0.7839 - val_loss: 0.3974 - val_auc: 0.7848\n",
      "Epoch 3/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3933 - auc: 0.7926\n",
      "Epoch 00003: val_auc did not improve from 0.78479\n",
      "588000/588000 [==============================] - 109s 185us/sample - loss: 0.3933 - auc: 0.7926 - val_loss: 0.3984 - val_auc: 0.7833\n",
      "Epoch 4/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3891 - auc: 0.7987\n",
      "Epoch 00004: val_auc did not improve from 0.78479\n",
      "588000/588000 [==============================] - 109s 185us/sample - loss: 0.3891 - auc: 0.7987 - val_loss: 0.3985 - val_auc: 0.7828\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3858 - auc: 0.8030Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00005: val_auc did not improve from 0.78479\n",
      "588000/588000 [==============================] - 109s 186us/sample - loss: 0.3858 - auc: 0.8030 - val_loss: 0.4000 - val_auc: 0.7809\n",
      "Epoch 00005: early stopping\n",
      "validation AUC fold 1 : 0.7848\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4327 - auc: 0.7387\n",
      "Epoch 00001: val_auc improved from -inf to 0.78833, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 131s 223us/sample - loss: 0.4326 - auc: 0.7387 - val_loss: 0.3969 - val_auc: 0.7883\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3960 - auc: 0.7901\n",
      "Epoch 00002: val_auc improved from 0.78833 to 0.79017, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 108s 184us/sample - loss: 0.3960 - auc: 0.7901 - val_loss: 0.3951 - val_auc: 0.7902\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3931 - auc: 0.7939\n",
      "Epoch 00003: val_auc did not improve from 0.79017\n",
      "588000/588000 [==============================] - 109s 185us/sample - loss: 0.3932 - auc: 0.7938 - val_loss: 0.3953 - val_auc: 0.7897\n",
      "Epoch 4/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3924 - auc: 0.7951\n",
      "Epoch 00004: val_auc did not improve from 0.79017\n",
      "588000/588000 [==============================] - 109s 185us/sample - loss: 0.3924 - auc: 0.7951 - val_loss: 0.3954 - val_auc: 0.7893\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3918 - auc: 0.7958\n",
      "Epoch 00005: val_auc did not improve from 0.79017\n",
      "588000/588000 [==============================] - 109s 185us/sample - loss: 0.3918 - auc: 0.7958 - val_loss: 0.3956 - val_auc: 0.7892\n",
      "Epoch 6/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3914 - auc: 0.7964Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00006: val_auc did not improve from 0.79017\n",
      "588000/588000 [==============================] - 109s 185us/sample - loss: 0.3914 - auc: 0.7963 - val_loss: 0.3956 - val_auc: 0.7888\n",
      "Epoch 00006: early stopping\n",
      "validation AUC fold 2 : 0.78984\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4897 - auc: 0.6707\n",
      "Epoch 00001: val_auc improved from -inf to 0.73138, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 132s 224us/sample - loss: 0.4897 - auc: 0.6707 - val_loss: 0.4342 - val_auc: 0.7314\n",
      "Epoch 2/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4161 - auc: 0.7624\n",
      "Epoch 00002: val_auc improved from 0.73138 to 0.76962, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 109s 186us/sample - loss: 0.4161 - auc: 0.7624 - val_loss: 0.4084 - val_auc: 0.7696\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3998 - auc: 0.7850\n",
      "Epoch 00003: val_auc improved from 0.76962 to 0.77859, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 109s 185us/sample - loss: 0.3998 - auc: 0.7850 - val_loss: 0.4015 - val_auc: 0.7786\n",
      "Epoch 4/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3947 - auc: 0.7916\n",
      "Epoch 00004: val_auc improved from 0.77859 to 0.78132, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 109s 185us/sample - loss: 0.3947 - auc: 0.7915 - val_loss: 0.3998 - val_auc: 0.7813\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3928 - auc: 0.7941\n",
      "Epoch 00005: val_auc improved from 0.78132 to 0.78264, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 109s 185us/sample - loss: 0.3928 - auc: 0.7941 - val_loss: 0.3991 - val_auc: 0.7826\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3916 - auc: 0.7959\n",
      "Epoch 00006: val_auc improved from 0.78264 to 0.78308, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 109s 185us/sample - loss: 0.3916 - auc: 0.7959 - val_loss: 0.3989 - val_auc: 0.7831\n",
      "Epoch 7/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3911 - auc: 0.7964\n",
      "Epoch 00007: val_auc improved from 0.78308 to 0.78344, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 109s 185us/sample - loss: 0.3911 - auc: 0.7964 - val_loss: 0.3988 - val_auc: 0.7834\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3907 - auc: 0.7968\n",
      "Epoch 00008: val_auc did not improve from 0.78344\n",
      "588000/588000 [==============================] - 109s 185us/sample - loss: 0.3908 - auc: 0.7968 - val_loss: 0.3989 - val_auc: 0.7832\n",
      "Epoch 9/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3906 - auc: 0.7970\n",
      "Epoch 00009: val_auc improved from 0.78344 to 0.78364, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 109s 185us/sample - loss: 0.3906 - auc: 0.7970 - val_loss: 0.3987 - val_auc: 0.7836\n",
      "Epoch 10/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3904 - auc: 0.7974\n",
      "Epoch 00010: val_auc did not improve from 0.78364\n",
      "588000/588000 [==============================] - 109s 185us/sample - loss: 0.3904 - auc: 0.7974 - val_loss: 0.3987 - val_auc: 0.7836\n",
      "Epoch 11/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3903 - auc: 0.7973\n",
      "Epoch 00011: val_auc did not improve from 0.78364\n",
      "588000/588000 [==============================] - 109s 185us/sample - loss: 0.3903 - auc: 0.7973 - val_loss: 0.3988 - val_auc: 0.7832\n",
      "Epoch 12/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3901 - auc: 0.7975\n",
      "Epoch 00012: val_auc did not improve from 0.78364\n",
      "588000/588000 [==============================] - 109s 185us/sample - loss: 0.3901 - auc: 0.7975 - val_loss: 0.3989 - val_auc: 0.7833\n",
      "Epoch 13/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3902 - auc: 0.7980Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00013: val_auc did not improve from 0.78364\n",
      "588000/588000 [==============================] - 109s 185us/sample - loss: 0.3902 - auc: 0.7980 - val_loss: 0.3987 - val_auc: 0.7833\n",
      "Epoch 00013: early stopping\n",
      "validation AUC fold 3 : 0.78455\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4977 - auc: 0.6748\n",
      "Epoch 00001: val_auc improved from -inf to 0.73840, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 133s 226us/sample - loss: 0.4976 - auc: 0.6749 - val_loss: 0.4341 - val_auc: 0.7384\n",
      "Epoch 2/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4162 - auc: 0.7644\n",
      "Epoch 00002: val_auc improved from 0.73840 to 0.77433, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 109s 186us/sample - loss: 0.4162 - auc: 0.7645 - val_loss: 0.4074 - val_auc: 0.7743\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4014 - auc: 0.7835\n",
      "Epoch 00003: val_auc improved from 0.77433 to 0.78242, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 109s 186us/sample - loss: 0.4014 - auc: 0.7835 - val_loss: 0.4012 - val_auc: 0.7824\n",
      "Epoch 4/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3963 - auc: 0.7899\n",
      "Epoch 00004: val_auc improved from 0.78242 to 0.78543, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 109s 186us/sample - loss: 0.3963 - auc: 0.7899 - val_loss: 0.3988 - val_auc: 0.7854\n",
      "Epoch 5/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3936 - auc: 0.7934\n",
      "Epoch 00005: val_auc improved from 0.78543 to 0.78618, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 109s 186us/sample - loss: 0.3935 - auc: 0.7935 - val_loss: 0.3980 - val_auc: 0.7862\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3920 - auc: 0.7954\n",
      "Epoch 00006: val_auc improved from 0.78618 to 0.78643, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 109s 186us/sample - loss: 0.3920 - auc: 0.7954 - val_loss: 0.3979 - val_auc: 0.7864\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3912 - auc: 0.7965\n",
      "Epoch 00007: val_auc did not improve from 0.78643\n",
      "588000/588000 [==============================] - 109s 186us/sample - loss: 0.3912 - auc: 0.7965 - val_loss: 0.3979 - val_auc: 0.7862\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3909 - auc: 0.7967\n",
      "Epoch 00008: val_auc did not improve from 0.78643\n",
      "588000/588000 [==============================] - 109s 186us/sample - loss: 0.3909 - auc: 0.7967 - val_loss: 0.3978 - val_auc: 0.7864\n",
      "Epoch 9/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3906 - auc: 0.7972\n",
      "Epoch 00009: val_auc did not improve from 0.78643\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3906 - auc: 0.7972 - val_loss: 0.3978 - val_auc: 0.7859\n",
      "Epoch 10/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3904 - auc: 0.7974Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.78643\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3904 - auc: 0.7974 - val_loss: 0.3979 - val_auc: 0.7858\n",
      "Epoch 00010: early stopping\n",
      "validation AUC fold 4 : 0.787\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4942 - auc: 0.6717\n",
      "Epoch 00001: val_auc improved from -inf to 0.75382, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 132s 225us/sample - loss: 0.4942 - auc: 0.6718 - val_loss: 0.4273 - val_auc: 0.7538\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4132 - auc: 0.7703\n",
      "Epoch 00002: val_auc improved from 0.75382 to 0.77877, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.4132 - auc: 0.7704 - val_loss: 0.4047 - val_auc: 0.7788\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3999 - auc: 0.7861\n",
      "Epoch 00003: val_auc improved from 0.77877 to 0.78364, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 109s 186us/sample - loss: 0.3999 - auc: 0.7861 - val_loss: 0.4009 - val_auc: 0.7836\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3958 - auc: 0.7909\n",
      "Epoch 00004: val_auc improved from 0.78364 to 0.78404, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 109s 186us/sample - loss: 0.3958 - auc: 0.7909 - val_loss: 0.4002 - val_auc: 0.7840\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3935 - auc: 0.7936\n",
      "Epoch 00005: val_auc did not improve from 0.78404\n",
      "588000/588000 [==============================] - 109s 186us/sample - loss: 0.3935 - auc: 0.7936 - val_loss: 0.4003 - val_auc: 0.7833\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3922 - auc: 0.7952\n",
      "Epoch 00006: val_auc did not improve from 0.78404\n",
      "588000/588000 [==============================] - 109s 186us/sample - loss: 0.3922 - auc: 0.7953 - val_loss: 0.4004 - val_auc: 0.7828\n",
      "Epoch 7/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3916 - auc: 0.7959Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.78404\n",
      "588000/588000 [==============================] - 109s 186us/sample - loss: 0.3916 - auc: 0.7959 - val_loss: 0.4006 - val_auc: 0.7823\n",
      "Epoch 00007: early stopping\n",
      "validation AUC fold 5 : 0.78391\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4998 - auc: 0.6678\n",
      "Epoch 00001: val_auc improved from -inf to 0.73799, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 133s 226us/sample - loss: 0.4997 - auc: 0.6678 - val_loss: 0.4319 - val_auc: 0.7380\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4181 - auc: 0.7586\n",
      "Epoch 00002: val_auc improved from 0.73799 to 0.77012, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 109s 186us/sample - loss: 0.4181 - auc: 0.7585 - val_loss: 0.4079 - val_auc: 0.7701\n",
      "Epoch 3/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4044 - auc: 0.7777\n",
      "Epoch 00003: val_auc improved from 0.77012 to 0.78182, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 109s 186us/sample - loss: 0.4044 - auc: 0.7778 - val_loss: 0.4006 - val_auc: 0.7818\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4002 - auc: 0.7835\n",
      "Epoch 00004: val_auc improved from 0.78182 to 0.78477, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 109s 186us/sample - loss: 0.4002 - auc: 0.7835 - val_loss: 0.3987 - val_auc: 0.7848\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3981 - auc: 0.7860\n",
      "Epoch 00005: val_auc improved from 0.78477 to 0.78550, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3981 - auc: 0.7861 - val_loss: 0.3980 - val_auc: 0.7855\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3971 - auc: 0.7875\n",
      "Epoch 00006: val_auc improved from 0.78550 to 0.78574, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3971 - auc: 0.7874 - val_loss: 0.3977 - val_auc: 0.7857\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3961 - auc: 0.7889\n",
      "Epoch 00007: val_auc improved from 0.78574 to 0.78604, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3961 - auc: 0.7889 - val_loss: 0.3976 - val_auc: 0.7860\n",
      "Epoch 8/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3949 - auc: 0.7906\n",
      "Epoch 00008: val_auc improved from 0.78604 to 0.78622, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3949 - auc: 0.7906 - val_loss: 0.3974 - val_auc: 0.7862\n",
      "Epoch 9/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3938 - auc: 0.7921\n",
      "Epoch 00009: val_auc improved from 0.78622 to 0.78673, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3939 - auc: 0.7921 - val_loss: 0.3971 - val_auc: 0.7867\n",
      "Epoch 10/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3931 - auc: 0.7934\n",
      "Epoch 00010: val_auc improved from 0.78673 to 0.78754, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3931 - auc: 0.7935 - val_loss: 0.3967 - val_auc: 0.7875\n",
      "Epoch 11/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3922 - auc: 0.7947\n",
      "Epoch 00011: val_auc improved from 0.78754 to 0.78782, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 109s 186us/sample - loss: 0.3922 - auc: 0.7947 - val_loss: 0.3966 - val_auc: 0.7878\n",
      "Epoch 12/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3918 - auc: 0.7949\n",
      "Epoch 00012: val_auc improved from 0.78782 to 0.78800, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3918 - auc: 0.7950 - val_loss: 0.3963 - val_auc: 0.7880\n",
      "Epoch 13/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3913 - auc: 0.7957\n",
      "Epoch 00013: val_auc improved from 0.78800 to 0.78815, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3913 - auc: 0.7957 - val_loss: 0.3961 - val_auc: 0.7882\n",
      "Epoch 14/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3910 - auc: 0.7964Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00014: val_auc improved from 0.78815 to 0.78848, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3910 - auc: 0.7965 - val_loss: 0.3960 - val_auc: 0.7885\n",
      "Epoch 00014: early stopping\n",
      "validation AUC fold 6 : 0.78834\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4975 - auc: 0.6514\n",
      "Epoch 00001: val_auc improved from -inf to 0.74390, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 132s 225us/sample - loss: 0.4975 - auc: 0.6514 - val_loss: 0.4338 - val_auc: 0.7439\n",
      "Epoch 2/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4155 - auc: 0.7671\n",
      "Epoch 00002: val_auc improved from 0.74390 to 0.77699, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.4155 - auc: 0.7672 - val_loss: 0.4066 - val_auc: 0.7770\n",
      "Epoch 3/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3997 - auc: 0.7864\n",
      "Epoch 00003: val_auc improved from 0.77699 to 0.78266, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3997 - auc: 0.7864 - val_loss: 0.4016 - val_auc: 0.7827\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3949 - auc: 0.7923\n",
      "Epoch 00004: val_auc improved from 0.78266 to 0.78403, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3949 - auc: 0.7923 - val_loss: 0.4002 - val_auc: 0.7840\n",
      "Epoch 5/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3927 - auc: 0.7946\n",
      "Epoch 00005: val_auc did not improve from 0.78403\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3927 - auc: 0.7946 - val_loss: 0.4000 - val_auc: 0.7837\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3915 - auc: 0.7962\n",
      "Epoch 00006: val_auc did not improve from 0.78403\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3915 - auc: 0.7963 - val_loss: 0.4002 - val_auc: 0.7831\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3910 - auc: 0.7966\n",
      "Epoch 00007: val_auc did not improve from 0.78403\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3910 - auc: 0.7966 - val_loss: 0.4002 - val_auc: 0.7831\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3906 - auc: 0.7971Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.78403\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3906 - auc: 0.7972 - val_loss: 0.4004 - val_auc: 0.7827\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 7 : 0.78391\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4977 - auc: 0.6227\n",
      "Epoch 00001: val_auc improved from -inf to 0.72804, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 133s 226us/sample - loss: 0.4977 - auc: 0.6227 - val_loss: 0.4380 - val_auc: 0.7280\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4174 - auc: 0.7621\n",
      "Epoch 00002: val_auc improved from 0.72804 to 0.77560, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.4174 - auc: 0.7621 - val_loss: 0.4080 - val_auc: 0.7756\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4009 - auc: 0.7843\n",
      "Epoch 00003: val_auc improved from 0.77560 to 0.78296, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.4009 - auc: 0.7843 - val_loss: 0.4024 - val_auc: 0.7830\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3961 - auc: 0.7907\n",
      "Epoch 00004: val_auc improved from 0.78296 to 0.78496, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3960 - auc: 0.7907 - val_loss: 0.4008 - val_auc: 0.7850\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3938 - auc: 0.7936\n",
      "Epoch 00005: val_auc improved from 0.78496 to 0.78537, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3937 - auc: 0.7936 - val_loss: 0.4003 - val_auc: 0.7854\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3925 - auc: 0.7950\n",
      "Epoch 00006: val_auc did not improve from 0.78537\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3925 - auc: 0.7950 - val_loss: 0.4000 - val_auc: 0.7851\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3919 - auc: 0.7957\n",
      "Epoch 00007: val_auc did not improve from 0.78537\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3919 - auc: 0.7957 - val_loss: 0.4001 - val_auc: 0.7845\n",
      "Epoch 8/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3913 - auc: 0.7961Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.78537\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3913 - auc: 0.7961 - val_loss: 0.3999 - val_auc: 0.7845\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 8 : 0.78569\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.5007 - auc: 0.6296\n",
      "Epoch 00001: val_auc improved from -inf to 0.73952, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 133s 227us/sample - loss: 0.5007 - auc: 0.6297 - val_loss: 0.4376 - val_auc: 0.7395\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4172 - auc: 0.7646\n",
      "Epoch 00002: val_auc improved from 0.73952 to 0.78303, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.4172 - auc: 0.7646 - val_loss: 0.4043 - val_auc: 0.7830\n",
      "Epoch 3/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4012 - auc: 0.7846\n",
      "Epoch 00003: val_auc improved from 0.78303 to 0.78935, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.4011 - auc: 0.7846 - val_loss: 0.3989 - val_auc: 0.7893\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3963 - auc: 0.7905\n",
      "Epoch 00004: val_auc improved from 0.78935 to 0.79002, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3964 - auc: 0.7904 - val_loss: 0.3976 - val_auc: 0.7900\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3940 - auc: 0.7932\n",
      "Epoch 00005: val_auc did not improve from 0.79002\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3940 - auc: 0.7932 - val_loss: 0.3974 - val_auc: 0.7894\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3927 - auc: 0.7949\n",
      "Epoch 00006: val_auc did not improve from 0.79002\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3928 - auc: 0.7949 - val_loss: 0.3973 - val_auc: 0.7892\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3921 - auc: 0.7955Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.79002\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3921 - auc: 0.7954 - val_loss: 0.3974 - val_auc: 0.7885\n",
      "Epoch 00007: early stopping\n",
      "validation AUC fold 9 : 0.79033\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4963 - auc: 0.6442\n",
      "Epoch 00001: val_auc improved from -inf to 0.73788, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 133s 226us/sample - loss: 0.4963 - auc: 0.6443 - val_loss: 0.4333 - val_auc: 0.7379\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4191 - auc: 0.7585\n",
      "Epoch 00002: val_auc improved from 0.73788 to 0.77427, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.4191 - auc: 0.7585 - val_loss: 0.4064 - val_auc: 0.7743\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4022 - auc: 0.7825\n",
      "Epoch 00003: val_auc improved from 0.77427 to 0.78370, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.4022 - auc: 0.7825 - val_loss: 0.3997 - val_auc: 0.7837\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3964 - auc: 0.7903\n",
      "Epoch 00004: val_auc improved from 0.78370 to 0.78614, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3964 - auc: 0.7902 - val_loss: 0.3982 - val_auc: 0.7861\n",
      "Epoch 5/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3940 - auc: 0.7934\n",
      "Epoch 00005: val_auc did not improve from 0.78614\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3941 - auc: 0.7934 - val_loss: 0.3980 - val_auc: 0.7859\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3926 - auc: 0.7949\n",
      "Epoch 00006: val_auc did not improve from 0.78614\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3926 - auc: 0.7949 - val_loss: 0.3980 - val_auc: 0.7860\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3919 - auc: 0.7958\n",
      "Epoch 00007: val_auc did not improve from 0.78614\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3920 - auc: 0.7958 - val_loss: 0.3980 - val_auc: 0.7857\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3913 - auc: 0.7965Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.78614\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3913 - auc: 0.7965 - val_loss: 0.3980 - val_auc: 0.7858\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 10 : 0.78467\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.5077 - auc: 0.6137\n",
      "Epoch 00001: val_auc improved from -inf to 0.73279, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 133s 227us/sample - loss: 0.5077 - auc: 0.6139 - val_loss: 0.4412 - val_auc: 0.7328\n",
      "Epoch 2/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4194 - auc: 0.7621\n",
      "Epoch 00002: val_auc improved from 0.73279 to 0.76949, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.4193 - auc: 0.7621 - val_loss: 0.4095 - val_auc: 0.7695\n",
      "Epoch 3/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4027 - auc: 0.7816\n",
      "Epoch 00003: val_auc improved from 0.76949 to 0.77560, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.4026 - auc: 0.7816 - val_loss: 0.4049 - val_auc: 0.7756\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3981 - auc: 0.7874\n",
      "Epoch 00004: val_auc improved from 0.77560 to 0.77790, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3981 - auc: 0.7874 - val_loss: 0.4033 - val_auc: 0.7779\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3956 - auc: 0.7903\n",
      "Epoch 00005: val_auc improved from 0.77790 to 0.77922, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3956 - auc: 0.7903 - val_loss: 0.4024 - val_auc: 0.7792\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3938 - auc: 0.7928\n",
      "Epoch 00006: val_auc improved from 0.77922 to 0.77990, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3938 - auc: 0.7928 - val_loss: 0.4018 - val_auc: 0.7799\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3926 - auc: 0.7944\n",
      "Epoch 00007: val_auc improved from 0.77990 to 0.78023, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3926 - auc: 0.7944 - val_loss: 0.4015 - val_auc: 0.7802\n",
      "Epoch 8/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3919 - auc: 0.7955\n",
      "Epoch 00008: val_auc improved from 0.78023 to 0.78085, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3919 - auc: 0.7955 - val_loss: 0.4013 - val_auc: 0.7808\n",
      "Epoch 9/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3912 - auc: 0.7964\n",
      "Epoch 00009: val_auc did not improve from 0.78085\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3912 - auc: 0.7964 - val_loss: 0.4014 - val_auc: 0.7808\n",
      "Epoch 10/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3910 - auc: 0.7969\n",
      "Epoch 00010: val_auc improved from 0.78085 to 0.78102, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3910 - auc: 0.7969 - val_loss: 0.4013 - val_auc: 0.7810\n",
      "Epoch 11/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3905 - auc: 0.7973Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.78102\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3906 - auc: 0.7973 - val_loss: 0.4013 - val_auc: 0.7810\n",
      "Epoch 00011: early stopping\n",
      "validation AUC fold 11 : 0.78088\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.5000 - auc: 0.6351\n",
      "Epoch 00001: val_auc improved from -inf to 0.74107, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 132s 225us/sample - loss: 0.5000 - auc: 0.6351 - val_loss: 0.4365 - val_auc: 0.7411\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4195 - auc: 0.7609\n",
      "Epoch 00002: val_auc improved from 0.74107 to 0.78402, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.4196 - auc: 0.7609 - val_loss: 0.4027 - val_auc: 0.7840\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4025 - auc: 0.7827\n",
      "Epoch 00003: val_auc improved from 0.78402 to 0.79299, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.4024 - auc: 0.7827 - val_loss: 0.3945 - val_auc: 0.7930\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3968 - auc: 0.7900\n",
      "Epoch 00004: val_auc improved from 0.79299 to 0.79534, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3968 - auc: 0.7900 - val_loss: 0.3921 - val_auc: 0.7953\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3943 - auc: 0.7932\n",
      "Epoch 00005: val_auc improved from 0.79534 to 0.79600, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3943 - auc: 0.7932 - val_loss: 0.3914 - val_auc: 0.7960\n",
      "Epoch 6/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3930 - auc: 0.7949\n",
      "Epoch 00006: val_auc improved from 0.79600 to 0.79603, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 109s 186us/sample - loss: 0.3930 - auc: 0.7949 - val_loss: 0.3914 - val_auc: 0.7960\n",
      "Epoch 7/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3922 - auc: 0.7954\n",
      "Epoch 00007: val_auc did not improve from 0.79603\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3922 - auc: 0.7954 - val_loss: 0.3915 - val_auc: 0.7960\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3917 - auc: 0.7961Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.79603\n",
      "588000/588000 [==============================] - 109s 186us/sample - loss: 0.3917 - auc: 0.7961 - val_loss: 0.3914 - val_auc: 0.7959\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 12 : 0.79702\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.5031 - auc: 0.5979\n",
      "Epoch 00001: val_auc improved from -inf to 0.72925, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 133s 227us/sample - loss: 0.5031 - auc: 0.5980 - val_loss: 0.4410 - val_auc: 0.7293\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4205 - auc: 0.7603\n",
      "Epoch 00002: val_auc improved from 0.72925 to 0.78091, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.4205 - auc: 0.7603 - val_loss: 0.4033 - val_auc: 0.7809\n",
      "Epoch 3/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4023 - auc: 0.7833\n",
      "Epoch 00003: val_auc improved from 0.78091 to 0.79031, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.4023 - auc: 0.7833 - val_loss: 0.3950 - val_auc: 0.7903\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3967 - auc: 0.7901\n",
      "Epoch 00004: val_auc improved from 0.79031 to 0.79336, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3967 - auc: 0.7901 - val_loss: 0.3925 - val_auc: 0.7934\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3941 - auc: 0.7932\n",
      "Epoch 00005: val_auc improved from 0.79336 to 0.79350, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3941 - auc: 0.7933 - val_loss: 0.3919 - val_auc: 0.7935\n",
      "Epoch 6/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3927 - auc: 0.7950\n",
      "Epoch 00006: val_auc did not improve from 0.79350\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3927 - auc: 0.7950 - val_loss: 0.3918 - val_auc: 0.7935\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3920 - auc: 0.7955\n",
      "Epoch 00007: val_auc improved from 0.79350 to 0.79367, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3920 - auc: 0.7955 - val_loss: 0.3917 - val_auc: 0.7937\n",
      "Epoch 8/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3916 - auc: 0.7961Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.79367\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3916 - auc: 0.7962 - val_loss: 0.3920 - val_auc: 0.7931\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 13 : 0.79353\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.5009 - auc: 0.6354\n",
      "Epoch 00001: val_auc improved from -inf to 0.74526, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 134s 227us/sample - loss: 0.5008 - auc: 0.6355 - val_loss: 0.4336 - val_auc: 0.7453\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4154 - auc: 0.7675\n",
      "Epoch 00002: val_auc improved from 0.74526 to 0.78245, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.4154 - auc: 0.7675 - val_loss: 0.4021 - val_auc: 0.7824\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4001 - auc: 0.7859\n",
      "Epoch 00003: val_auc improved from 0.78245 to 0.78761, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.4002 - auc: 0.7859 - val_loss: 0.3971 - val_auc: 0.7876\n",
      "Epoch 4/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3955 - auc: 0.7918\n",
      "Epoch 00004: val_auc improved from 0.78761 to 0.78853, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3955 - auc: 0.7918 - val_loss: 0.3958 - val_auc: 0.7885\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3933 - auc: 0.7945\n",
      "Epoch 00005: val_auc did not improve from 0.78853\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3933 - auc: 0.7945 - val_loss: 0.3956 - val_auc: 0.7885\n",
      "Epoch 6/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3921 - auc: 0.7958\n",
      "Epoch 00006: val_auc did not improve from 0.78853\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3922 - auc: 0.7958 - val_loss: 0.3956 - val_auc: 0.7881\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3916 - auc: 0.7962Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.78853\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3916 - auc: 0.7962 - val_loss: 0.3957 - val_auc: 0.7877\n",
      "Epoch 00007: early stopping\n",
      "validation AUC fold 14 : 0.78946\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.5079 - auc: 0.6136\n",
      "Epoch 00001: val_auc improved from -inf to 0.73941, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 133s 226us/sample - loss: 0.5079 - auc: 0.6136 - val_loss: 0.4426 - val_auc: 0.7394\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4203 - auc: 0.7634\n",
      "Epoch 00002: val_auc improved from 0.73941 to 0.78410, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.4203 - auc: 0.7634 - val_loss: 0.4058 - val_auc: 0.7841\n",
      "Epoch 3/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4013 - auc: 0.7856\n",
      "Epoch 00003: val_auc improved from 0.78410 to 0.79170, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.4012 - auc: 0.7855 - val_loss: 0.3981 - val_auc: 0.7917\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3961 - auc: 0.7915\n",
      "Epoch 00004: val_auc improved from 0.79170 to 0.79429, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3961 - auc: 0.7914 - val_loss: 0.3955 - val_auc: 0.7943\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3938 - auc: 0.7938\n",
      "Epoch 00005: val_auc improved from 0.79429 to 0.79469, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3938 - auc: 0.7938 - val_loss: 0.3945 - val_auc: 0.7947\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3925 - auc: 0.7954\n",
      "Epoch 00006: val_auc did not improve from 0.79469\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3925 - auc: 0.7954 - val_loss: 0.3940 - val_auc: 0.7943\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3918 - auc: 0.7962\n",
      "Epoch 00007: val_auc did not improve from 0.79469\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3918 - auc: 0.7962 - val_loss: 0.3936 - val_auc: 0.7946\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3915 - auc: 0.7962Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.79469\n",
      "588000/588000 [==============================] - 110s 186us/sample - loss: 0.3916 - auc: 0.7962 - val_loss: 0.3936 - val_auc: 0.7941\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 15 : 0.79399\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.5048 - auc: 0.6076\n",
      "Epoch 00001: val_auc improved from -inf to 0.75371, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 134s 228us/sample - loss: 0.5048 - auc: 0.6077 - val_loss: 0.4386 - val_auc: 0.7537\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4203 - auc: 0.7634\n",
      "Epoch 00002: val_auc improved from 0.75371 to 0.78488, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.4203 - auc: 0.7634 - val_loss: 0.4040 - val_auc: 0.7849\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4030 - auc: 0.7821\n",
      "Epoch 00003: val_auc improved from 0.78488 to 0.79103, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.4030 - auc: 0.7821 - val_loss: 0.3972 - val_auc: 0.7910\n",
      "Epoch 4/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3979 - auc: 0.7884\n",
      "Epoch 00004: val_auc improved from 0.79103 to 0.79304, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3979 - auc: 0.7884 - val_loss: 0.3947 - val_auc: 0.7930\n",
      "Epoch 5/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3950 - auc: 0.7919\n",
      "Epoch 00005: val_auc improved from 0.79304 to 0.79414, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3951 - auc: 0.7919 - val_loss: 0.3934 - val_auc: 0.7941\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3936 - auc: 0.7939\n",
      "Epoch 00006: val_auc did not improve from 0.79414\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3936 - auc: 0.7939 - val_loss: 0.3931 - val_auc: 0.7939\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3924 - auc: 0.7951\n",
      "Epoch 00007: val_auc did not improve from 0.79414\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3924 - auc: 0.7951 - val_loss: 0.3929 - val_auc: 0.7939\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3919 - auc: 0.7957\n",
      "Epoch 00008: val_auc did not improve from 0.79414\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3919 - auc: 0.7957 - val_loss: 0.3928 - val_auc: 0.7938\n",
      "Epoch 9/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3916 - auc: 0.7964Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.79414\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3916 - auc: 0.7964 - val_loss: 0.3926 - val_auc: 0.7938\n",
      "Epoch 00009: early stopping\n",
      "validation AUC fold 16 : 0.79507\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4963 - auc: 0.6328\n",
      "Epoch 00001: val_auc improved from -inf to 0.74884, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 134s 227us/sample - loss: 0.4963 - auc: 0.6328 - val_loss: 0.4344 - val_auc: 0.7488\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4161 - auc: 0.7667\n",
      "Epoch 00002: val_auc improved from 0.74884 to 0.78482, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.4161 - auc: 0.7667 - val_loss: 0.4027 - val_auc: 0.7848\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4011 - auc: 0.7847\n",
      "Epoch 00003: val_auc improved from 0.78482 to 0.78906, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.4011 - auc: 0.7847 - val_loss: 0.3976 - val_auc: 0.7891\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3966 - auc: 0.7901\n",
      "Epoch 00004: val_auc improved from 0.78906 to 0.78968, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3966 - auc: 0.7901 - val_loss: 0.3964 - val_auc: 0.7897\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3941 - auc: 0.7934\n",
      "Epoch 00005: val_auc did not improve from 0.78968\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3941 - auc: 0.7934 - val_loss: 0.3962 - val_auc: 0.7891\n",
      "Epoch 6/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3928 - auc: 0.7949\n",
      "Epoch 00006: val_auc did not improve from 0.78968\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3928 - auc: 0.7949 - val_loss: 0.3964 - val_auc: 0.7885\n",
      "Epoch 7/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3921 - auc: 0.7954Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00007: val_auc did not improve from 0.78968\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3921 - auc: 0.7954 - val_loss: 0.3967 - val_auc: 0.7880\n",
      "Epoch 00007: early stopping\n",
      "validation AUC fold 17 : 0.78987\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.5059 - auc: 0.6394\n",
      "Epoch 00001: val_auc improved from -inf to 0.72895, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 134s 227us/sample - loss: 0.5059 - auc: 0.6394 - val_loss: 0.4393 - val_auc: 0.7290\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4199 - auc: 0.7579\n",
      "Epoch 00002: val_auc improved from 0.72895 to 0.77558, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.4199 - auc: 0.7578 - val_loss: 0.4068 - val_auc: 0.7756\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4016 - auc: 0.7828\n",
      "Epoch 00003: val_auc improved from 0.77558 to 0.78672, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.4016 - auc: 0.7828 - val_loss: 0.3984 - val_auc: 0.7867\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3962 - auc: 0.7898\n",
      "Epoch 00004: val_auc improved from 0.78672 to 0.79086, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3962 - auc: 0.7898 - val_loss: 0.3955 - val_auc: 0.7909\n",
      "Epoch 5/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3936 - auc: 0.7932\n",
      "Epoch 00005: val_auc improved from 0.79086 to 0.79201, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3936 - auc: 0.7932 - val_loss: 0.3944 - val_auc: 0.7920\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3924 - auc: 0.7948\n",
      "Epoch 00006: val_auc improved from 0.79201 to 0.79250, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3924 - auc: 0.7948 - val_loss: 0.3939 - val_auc: 0.7925\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3915 - auc: 0.7958\n",
      "Epoch 00007: val_auc improved from 0.79250 to 0.79259, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3915 - auc: 0.7958 - val_loss: 0.3938 - val_auc: 0.7926\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3910 - auc: 0.7963\n",
      "Epoch 00008: val_auc improved from 0.79259 to 0.79265, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3910 - auc: 0.7963 - val_loss: 0.3937 - val_auc: 0.7927\n",
      "Epoch 9/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3907 - auc: 0.7970Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.79265\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3907 - auc: 0.7970 - val_loss: 0.3939 - val_auc: 0.7924\n",
      "Epoch 00009: early stopping\n",
      "validation AUC fold 18 : 0.79215\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4939 - auc: 0.6525\n",
      "Epoch 00001: val_auc improved from -inf to 0.75349, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 134s 228us/sample - loss: 0.4938 - auc: 0.6525 - val_loss: 0.4296 - val_auc: 0.7535\n",
      "Epoch 2/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4159 - auc: 0.7645\n",
      "Epoch 00002: val_auc improved from 0.75349 to 0.78894, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.4159 - auc: 0.7646 - val_loss: 0.4000 - val_auc: 0.7889\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4008 - auc: 0.7841\n",
      "Epoch 00003: val_auc improved from 0.78894 to 0.79585, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.4008 - auc: 0.7841 - val_loss: 0.3938 - val_auc: 0.7958\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3961 - auc: 0.7905\n",
      "Epoch 00004: val_auc improved from 0.79585 to 0.79706, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3960 - auc: 0.7905 - val_loss: 0.3922 - val_auc: 0.7971\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3936 - auc: 0.7938\n",
      "Epoch 00005: val_auc improved from 0.79706 to 0.79731, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3936 - auc: 0.7937 - val_loss: 0.3918 - val_auc: 0.7973\n",
      "Epoch 6/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3924 - auc: 0.7950\n",
      "Epoch 00006: val_auc did not improve from 0.79731\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3925 - auc: 0.7950 - val_loss: 0.3921 - val_auc: 0.7966\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3921 - auc: 0.7954\n",
      "Epoch 00007: val_auc did not improve from 0.79731\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3921 - auc: 0.7954 - val_loss: 0.3920 - val_auc: 0.7964\n",
      "Epoch 8/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3914 - auc: 0.7964Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.79731\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3914 - auc: 0.7963 - val_loss: 0.3923 - val_auc: 0.7959\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 19 : 0.79714\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.5021 - auc: 0.6273\n",
      "Epoch 00001: val_auc improved from -inf to 0.73694, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 134s 228us/sample - loss: 0.5021 - auc: 0.6273 - val_loss: 0.4378 - val_auc: 0.7369\n",
      "Epoch 2/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4183 - auc: 0.7632\n",
      "Epoch 00002: val_auc improved from 0.73694 to 0.78206, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.4182 - auc: 0.7632 - val_loss: 0.4051 - val_auc: 0.7821\n",
      "Epoch 3/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4009 - auc: 0.7854\n",
      "Epoch 00003: val_auc improved from 0.78206 to 0.78686, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.4009 - auc: 0.7854 - val_loss: 0.3998 - val_auc: 0.7869\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3962 - auc: 0.7911\n",
      "Epoch 00004: val_auc improved from 0.78686 to 0.78870, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3962 - auc: 0.7911 - val_loss: 0.3981 - val_auc: 0.7887\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3939 - auc: 0.7937\n",
      "Epoch 00005: val_auc improved from 0.78870 to 0.78901, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3940 - auc: 0.7937 - val_loss: 0.3974 - val_auc: 0.7890\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3928 - auc: 0.7949\n",
      "Epoch 00006: val_auc improved from 0.78901 to 0.78933, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3928 - auc: 0.7948 - val_loss: 0.3969 - val_auc: 0.7893\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3920 - auc: 0.7957\n",
      "Epoch 00007: val_auc improved from 0.78933 to 0.78950, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3920 - auc: 0.7957 - val_loss: 0.3967 - val_auc: 0.7895\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3915 - auc: 0.7961Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.78950\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3915 - auc: 0.7961 - val_loss: 0.3966 - val_auc: 0.7891\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 20 : 0.78889\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4940 - auc: 0.6567\n",
      "Epoch 00001: val_auc improved from -inf to 0.74215, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 134s 228us/sample - loss: 0.4940 - auc: 0.6567 - val_loss: 0.4314 - val_auc: 0.7422\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4154 - auc: 0.7650\n",
      "Epoch 00002: val_auc improved from 0.74215 to 0.77644, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.4154 - auc: 0.7650 - val_loss: 0.4059 - val_auc: 0.7764\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4005 - auc: 0.7843\n",
      "Epoch 00003: val_auc improved from 0.77644 to 0.78369, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.4005 - auc: 0.7843 - val_loss: 0.4004 - val_auc: 0.7837\n",
      "Epoch 4/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3956 - auc: 0.7907\n",
      "Epoch 00004: val_auc improved from 0.78369 to 0.78650, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3956 - auc: 0.7907 - val_loss: 0.3983 - val_auc: 0.7865\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3931 - auc: 0.7940\n",
      "Epoch 00005: val_auc improved from 0.78650 to 0.78681, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3931 - auc: 0.7940 - val_loss: 0.3978 - val_auc: 0.7868\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3919 - auc: 0.7952\n",
      "Epoch 00006: val_auc did not improve from 0.78681\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3919 - auc: 0.7952 - val_loss: 0.3977 - val_auc: 0.7865\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3911 - auc: 0.7963\n",
      "Epoch 00007: val_auc did not improve from 0.78681\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3911 - auc: 0.7963 - val_loss: 0.3977 - val_auc: 0.7866\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3907 - auc: 0.7972Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.78681\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3907 - auc: 0.7972 - val_loss: 0.3978 - val_auc: 0.7864\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 21 : 0.78618\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.5058 - auc: 0.6171\n",
      "Epoch 00001: val_auc improved from -inf to 0.72528, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 134s 228us/sample - loss: 0.5057 - auc: 0.6171 - val_loss: 0.4423 - val_auc: 0.7253\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4215 - auc: 0.7560\n",
      "Epoch 00002: val_auc improved from 0.72528 to 0.78425, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.4215 - auc: 0.7561 - val_loss: 0.4022 - val_auc: 0.7842\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4028 - auc: 0.7818\n",
      "Epoch 00003: val_auc improved from 0.78425 to 0.79325, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.4027 - auc: 0.7818 - val_loss: 0.3944 - val_auc: 0.7933\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3974 - auc: 0.7890\n",
      "Epoch 00004: val_auc improved from 0.79325 to 0.79554, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3974 - auc: 0.7890 - val_loss: 0.3924 - val_auc: 0.7955\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3946 - auc: 0.7923\n",
      "Epoch 00005: val_auc improved from 0.79554 to 0.79616, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3947 - auc: 0.7923 - val_loss: 0.3915 - val_auc: 0.7962\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3934 - auc: 0.7936\n",
      "Epoch 00006: val_auc did not improve from 0.79616\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3934 - auc: 0.7936 - val_loss: 0.3915 - val_auc: 0.7961\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3925 - auc: 0.7948\n",
      "Epoch 00007: val_auc did not improve from 0.79616\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3925 - auc: 0.7948 - val_loss: 0.3915 - val_auc: 0.7957\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3920 - auc: 0.7955Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.79616\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3920 - auc: 0.7954 - val_loss: 0.3914 - val_auc: 0.7957\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 22 : 0.79656\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.5057 - auc: 0.6054\n",
      "Epoch 00001: val_auc improved from -inf to 0.72972, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 134s 229us/sample - loss: 0.5057 - auc: 0.6055 - val_loss: 0.4433 - val_auc: 0.7297\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4223 - auc: 0.7571\n",
      "Epoch 00002: val_auc improved from 0.72972 to 0.77484, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.4223 - auc: 0.7571 - val_loss: 0.4091 - val_auc: 0.7748\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4050 - auc: 0.7788\n",
      "Epoch 00003: val_auc improved from 0.77484 to 0.78008, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.4050 - auc: 0.7788 - val_loss: 0.4036 - val_auc: 0.7801\n",
      "Epoch 4/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4011 - auc: 0.7834\n",
      "Epoch 00004: val_auc improved from 0.78008 to 0.78165, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.4011 - auc: 0.7834 - val_loss: 0.4020 - val_auc: 0.7816\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3991 - auc: 0.7857\n",
      "Epoch 00005: val_auc improved from 0.78165 to 0.78205, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3991 - auc: 0.7856 - val_loss: 0.4014 - val_auc: 0.7821\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3976 - auc: 0.7877\n",
      "Epoch 00006: val_auc did not improve from 0.78205\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3976 - auc: 0.7877 - val_loss: 0.4009 - val_auc: 0.7820\n",
      "Epoch 7/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3963 - auc: 0.7892\n",
      "Epoch 00007: val_auc improved from 0.78205 to 0.78243, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3963 - auc: 0.7892 - val_loss: 0.4005 - val_auc: 0.7824\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3950 - auc: 0.7910\n",
      "Epoch 00008: val_auc improved from 0.78243 to 0.78288, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3950 - auc: 0.7909 - val_loss: 0.4000 - val_auc: 0.7829\n",
      "Epoch 9/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3941 - auc: 0.7923\n",
      "Epoch 00009: val_auc improved from 0.78288 to 0.78361, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3940 - auc: 0.7923 - val_loss: 0.3994 - val_auc: 0.7836\n",
      "Epoch 10/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3931 - auc: 0.7935\n",
      "Epoch 00010: val_auc improved from 0.78361 to 0.78405, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3931 - auc: 0.7936 - val_loss: 0.3989 - val_auc: 0.7841\n",
      "Epoch 11/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3926 - auc: 0.7942\n",
      "Epoch 00011: val_auc improved from 0.78405 to 0.78464, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3926 - auc: 0.7942 - val_loss: 0.3985 - val_auc: 0.7846\n",
      "Epoch 12/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3921 - auc: 0.7950\n",
      "Epoch 00012: val_auc improved from 0.78464 to 0.78525, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3921 - auc: 0.7950 - val_loss: 0.3981 - val_auc: 0.7853\n",
      "Epoch 13/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3917 - auc: 0.7956\n",
      "Epoch 00013: val_auc improved from 0.78525 to 0.78589, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3917 - auc: 0.7956 - val_loss: 0.3975 - val_auc: 0.7859\n",
      "Epoch 14/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3913 - auc: 0.7961\n",
      "Epoch 00014: val_auc improved from 0.78589 to 0.78639, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3913 - auc: 0.7961 - val_loss: 0.3973 - val_auc: 0.7864\n",
      "Epoch 15/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3910 - auc: 0.7965\n",
      "Epoch 00015: val_auc improved from 0.78639 to 0.78669, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3910 - auc: 0.7965 - val_loss: 0.3970 - val_auc: 0.7867\n",
      "validation AUC fold 23 : 0.78721\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.5002 - auc: 0.6368\n",
      "Epoch 00001: val_auc improved from -inf to 0.71285, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 134s 228us/sample - loss: 0.5002 - auc: 0.6368 - val_loss: 0.4428 - val_auc: 0.7129\n",
      "Epoch 2/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4228 - auc: 0.7518\n",
      "Epoch 00002: val_auc improved from 0.71285 to 0.76852, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.4228 - auc: 0.7518 - val_loss: 0.4105 - val_auc: 0.7685\n",
      "Epoch 3/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4032 - auc: 0.7806\n",
      "Epoch 00003: val_auc improved from 0.76852 to 0.78116, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.4032 - auc: 0.7805 - val_loss: 0.4023 - val_auc: 0.7812\n",
      "Epoch 4/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3965 - auc: 0.7898\n",
      "Epoch 00004: val_auc improved from 0.78116 to 0.78403, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3965 - auc: 0.7898 - val_loss: 0.4002 - val_auc: 0.7840\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3937 - auc: 0.7935\n",
      "Epoch 00005: val_auc improved from 0.78403 to 0.78480, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3937 - auc: 0.7936 - val_loss: 0.3998 - val_auc: 0.7848\n",
      "Epoch 6/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3924 - auc: 0.7951\n",
      "Epoch 00006: val_auc did not improve from 0.78480\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3924 - auc: 0.7952 - val_loss: 0.3999 - val_auc: 0.7843\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3917 - auc: 0.7963\n",
      "Epoch 00007: val_auc did not improve from 0.78480\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3917 - auc: 0.7963 - val_loss: 0.4001 - val_auc: 0.7839\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3911 - auc: 0.7969Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.78480\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3911 - auc: 0.7969 - val_loss: 0.4001 - val_auc: 0.7835\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 24 : 0.78455\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4890 - auc: 0.6654\n",
      "Epoch 00001: val_auc improved from -inf to 0.74565, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 134s 228us/sample - loss: 0.4889 - auc: 0.6654 - val_loss: 0.4294 - val_auc: 0.7457\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4131 - auc: 0.7693\n",
      "Epoch 00002: val_auc improved from 0.74565 to 0.77845, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.4131 - auc: 0.7693 - val_loss: 0.4046 - val_auc: 0.7784\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4000 - auc: 0.7859\n",
      "Epoch 00003: val_auc improved from 0.77845 to 0.78475, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.4000 - auc: 0.7859 - val_loss: 0.4001 - val_auc: 0.7848\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3955 - auc: 0.7915\n",
      "Epoch 00004: val_auc improved from 0.78475 to 0.78593, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3955 - auc: 0.7915 - val_loss: 0.3989 - val_auc: 0.7859\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3933 - auc: 0.7940\n",
      "Epoch 00005: val_auc did not improve from 0.78593\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3933 - auc: 0.7940 - val_loss: 0.3987 - val_auc: 0.7858\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3922 - auc: 0.7957\n",
      "Epoch 00006: val_auc did not improve from 0.78593\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3922 - auc: 0.7957 - val_loss: 0.3988 - val_auc: 0.7851\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3917 - auc: 0.7962\n",
      "Epoch 00007: val_auc did not improve from 0.78593\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3917 - auc: 0.7962 - val_loss: 0.3987 - val_auc: 0.7848\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3913 - auc: 0.7967Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.78593\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3913 - auc: 0.7967 - val_loss: 0.3988 - val_auc: 0.7843\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 25 : 0.78559\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4979 - auc: 0.6414\n",
      "Epoch 00001: val_auc improved from -inf to 0.73765, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 134s 228us/sample - loss: 0.4979 - auc: 0.6414 - val_loss: 0.4365 - val_auc: 0.7376\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4174 - auc: 0.7626\n",
      "Epoch 00002: val_auc improved from 0.73765 to 0.77452, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.4174 - auc: 0.7626 - val_loss: 0.4087 - val_auc: 0.7745\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4017 - auc: 0.7839\n",
      "Epoch 00003: val_auc improved from 0.77452 to 0.78078, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.4018 - auc: 0.7839 - val_loss: 0.4033 - val_auc: 0.7808\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3965 - auc: 0.7905\n",
      "Epoch 00004: val_auc improved from 0.78078 to 0.78282, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3965 - auc: 0.7905 - val_loss: 0.4017 - val_auc: 0.7828\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3941 - auc: 0.7934\n",
      "Epoch 00005: val_auc improved from 0.78282 to 0.78329, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3941 - auc: 0.7934 - val_loss: 0.4013 - val_auc: 0.7833\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3930 - auc: 0.7944\n",
      "Epoch 00006: val_auc did not improve from 0.78329\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3930 - auc: 0.7944 - val_loss: 0.4011 - val_auc: 0.7830\n",
      "Epoch 7/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3920 - auc: 0.7954\n",
      "Epoch 00007: val_auc did not improve from 0.78329\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3920 - auc: 0.7954 - val_loss: 0.4011 - val_auc: 0.7831\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3915 - auc: 0.7964Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.78329\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3915 - auc: 0.7964 - val_loss: 0.4011 - val_auc: 0.7827\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 26 : 0.78297\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.5026 - auc: 0.6416\n",
      "Epoch 00001: val_auc improved from -inf to 0.73116, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 135s 229us/sample - loss: 0.5026 - auc: 0.6416 - val_loss: 0.4371 - val_auc: 0.7312\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4169 - auc: 0.7641\n",
      "Epoch 00002: val_auc improved from 0.73116 to 0.76822, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.4169 - auc: 0.7640 - val_loss: 0.4111 - val_auc: 0.7682\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4008 - auc: 0.7842\n",
      "Epoch 00003: val_auc improved from 0.76822 to 0.77401, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.4008 - auc: 0.7842 - val_loss: 0.4069 - val_auc: 0.7740\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3961 - auc: 0.7901\n",
      "Epoch 00004: val_auc improved from 0.77401 to 0.77574, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3961 - auc: 0.7901 - val_loss: 0.4058 - val_auc: 0.7757\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3935 - auc: 0.7933\n",
      "Epoch 00005: val_auc improved from 0.77574 to 0.77581, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3935 - auc: 0.7933 - val_loss: 0.4056 - val_auc: 0.7758\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3922 - auc: 0.7948\n",
      "Epoch 00006: val_auc improved from 0.77581 to 0.77593, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3922 - auc: 0.7948 - val_loss: 0.4055 - val_auc: 0.7759\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3916 - auc: 0.7955\n",
      "Epoch 00007: val_auc did not improve from 0.77593\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3916 - auc: 0.7955 - val_loss: 0.4057 - val_auc: 0.7754\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3911 - auc: 0.7964Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.77593\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3911 - auc: 0.7964 - val_loss: 0.4057 - val_auc: 0.7754\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 27 : 0.77635\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4996 - auc: 0.6511\n",
      "Epoch 00001: val_auc improved from -inf to 0.73880, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 134s 228us/sample - loss: 0.4995 - auc: 0.6511 - val_loss: 0.4322 - val_auc: 0.7388\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4168 - auc: 0.7615\n",
      "Epoch 00002: val_auc improved from 0.73880 to 0.78109, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.4168 - auc: 0.7615 - val_loss: 0.4029 - val_auc: 0.7811\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4024 - auc: 0.7810\n",
      "Epoch 00003: val_auc improved from 0.78109 to 0.78748, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.4024 - auc: 0.7811 - val_loss: 0.3969 - val_auc: 0.7875\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3972 - auc: 0.7881\n",
      "Epoch 00004: val_auc improved from 0.78748 to 0.79012, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3972 - auc: 0.7881 - val_loss: 0.3947 - val_auc: 0.7901\n",
      "Epoch 5/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3940 - auc: 0.7924\n",
      "Epoch 00005: val_auc improved from 0.79012 to 0.79089, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3940 - auc: 0.7924 - val_loss: 0.3941 - val_auc: 0.7909\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3923 - auc: 0.7948\n",
      "Epoch 00006: val_auc did not improve from 0.79089\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3923 - auc: 0.7948 - val_loss: 0.3940 - val_auc: 0.7909\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3914 - auc: 0.7958\n",
      "Epoch 00007: val_auc did not improve from 0.79089\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3914 - auc: 0.7958 - val_loss: 0.3940 - val_auc: 0.7905\n",
      "Epoch 8/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3909 - auc: 0.7963Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.79089\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3909 - auc: 0.7963 - val_loss: 0.3942 - val_auc: 0.7902\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 28 : 0.79109\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4995 - auc: 0.6493\n",
      "Epoch 00001: val_auc improved from -inf to 0.73146, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 134s 228us/sample - loss: 0.4995 - auc: 0.6494 - val_loss: 0.4370 - val_auc: 0.7315\n",
      "Epoch 2/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4173 - auc: 0.7646\n",
      "Epoch 00002: val_auc improved from 0.73146 to 0.76713, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.4173 - auc: 0.7646 - val_loss: 0.4113 - val_auc: 0.7671\n",
      "Epoch 3/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4028 - auc: 0.7817\n",
      "Epoch 00003: val_auc improved from 0.76713 to 0.77592, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.4028 - auc: 0.7817 - val_loss: 0.4052 - val_auc: 0.7759\n",
      "Epoch 4/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3974 - auc: 0.7887\n",
      "Epoch 00004: val_auc improved from 0.77592 to 0.77936, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3973 - auc: 0.7887 - val_loss: 0.4026 - val_auc: 0.7794\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3942 - auc: 0.7927\n",
      "Epoch 00005: val_auc improved from 0.77936 to 0.78158, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3942 - auc: 0.7927 - val_loss: 0.4011 - val_auc: 0.7816\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3925 - auc: 0.7950\n",
      "Epoch 00006: val_auc improved from 0.78158 to 0.78188, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3925 - auc: 0.7950 - val_loss: 0.4008 - val_auc: 0.7819\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3915 - auc: 0.7960\n",
      "Epoch 00007: val_auc did not improve from 0.78188\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3915 - auc: 0.7960 - val_loss: 0.4008 - val_auc: 0.7817\n",
      "Epoch 8/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3909 - auc: 0.7967\n",
      "Epoch 00008: val_auc did not improve from 0.78188\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3910 - auc: 0.7967 - val_loss: 0.4009 - val_auc: 0.7817\n",
      "Epoch 9/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3906 - auc: 0.7972Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.78188\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3906 - auc: 0.7972 - val_loss: 0.4010 - val_auc: 0.7816\n",
      "Epoch 00009: early stopping\n",
      "validation AUC fold 29 : 0.7815\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4956 - auc: 0.6414\n",
      "Epoch 00001: val_auc improved from -inf to 0.74904, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 134s 227us/sample - loss: 0.4955 - auc: 0.6414 - val_loss: 0.4327 - val_auc: 0.7490\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4152 - auc: 0.7672\n",
      "Epoch 00002: val_auc improved from 0.74904 to 0.78449, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.4152 - auc: 0.7672 - val_loss: 0.4013 - val_auc: 0.7845\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3996 - auc: 0.7867\n",
      "Epoch 00003: val_auc improved from 0.78449 to 0.79066, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3996 - auc: 0.7867 - val_loss: 0.3953 - val_auc: 0.7907\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3954 - auc: 0.7917\n",
      "Epoch 00004: val_auc improved from 0.79066 to 0.79246, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3954 - auc: 0.7917 - val_loss: 0.3934 - val_auc: 0.7925\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3934 - auc: 0.7940\n",
      "Epoch 00005: val_auc improved from 0.79246 to 0.79339, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3934 - auc: 0.7941 - val_loss: 0.3927 - val_auc: 0.7934\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3924 - auc: 0.7953\n",
      "Epoch 00006: val_auc did not improve from 0.79339\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3925 - auc: 0.7953 - val_loss: 0.3925 - val_auc: 0.7931\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3918 - auc: 0.7960\n",
      "Epoch 00007: val_auc did not improve from 0.79339\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3918 - auc: 0.7960 - val_loss: 0.3926 - val_auc: 0.7931\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3914 - auc: 0.7964Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.79339\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3914 - auc: 0.7964 - val_loss: 0.3926 - val_auc: 0.7930\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 30 : 0.79326\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4971 - auc: 0.6578\n",
      "Epoch 00001: val_auc improved from -inf to 0.75674, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 135s 229us/sample - loss: 0.4970 - auc: 0.6578 - val_loss: 0.4301 - val_auc: 0.7567\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4156 - auc: 0.7665- ETA: 2\n",
      "Epoch 00002: val_auc improved from 0.75674 to 0.77891, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.4156 - auc: 0.7664 - val_loss: 0.4067 - val_auc: 0.7789\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4021 - auc: 0.7830\n",
      "Epoch 00003: val_auc improved from 0.77891 to 0.78318, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.4021 - auc: 0.7830 - val_loss: 0.4022 - val_auc: 0.7832\n",
      "Epoch 4/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3972 - auc: 0.7891\n",
      "Epoch 00004: val_auc improved from 0.78318 to 0.78483, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3971 - auc: 0.7891 - val_loss: 0.4006 - val_auc: 0.7848\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3942 - auc: 0.7930\n",
      "Epoch 00005: val_auc did not improve from 0.78483\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3942 - auc: 0.7930 - val_loss: 0.4000 - val_auc: 0.7848\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3928 - auc: 0.7946\n",
      "Epoch 00006: val_auc did not improve from 0.78483\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.3929 - auc: 0.7945 - val_loss: 0.4000 - val_auc: 0.7845\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3918 - auc: 0.7959\n",
      "Epoch 00007: val_auc did not improve from 0.78483\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3919 - auc: 0.7958 - val_loss: 0.4002 - val_auc: 0.7841\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3914 - auc: 0.7962Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.78483\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3914 - auc: 0.7963 - val_loss: 0.4002 - val_auc: 0.7841\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 31 : 0.78453\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.5038 - auc: 0.6148\n",
      "Epoch 00001: val_auc improved from -inf to 0.73179, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 135s 229us/sample - loss: 0.5038 - auc: 0.6149 - val_loss: 0.4423 - val_auc: 0.7318\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4194 - auc: 0.7622\n",
      "Epoch 00002: val_auc improved from 0.73179 to 0.77905, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.4193 - auc: 0.7622 - val_loss: 0.4061 - val_auc: 0.7791\n",
      "Epoch 3/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4006 - auc: 0.7856\n",
      "Epoch 00003: val_auc improved from 0.77905 to 0.78685, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.4006 - auc: 0.7856 - val_loss: 0.3996 - val_auc: 0.7869\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3959 - auc: 0.7916\n",
      "Epoch 00004: val_auc improved from 0.78685 to 0.78905, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3959 - auc: 0.7916 - val_loss: 0.3978 - val_auc: 0.7890\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3936 - auc: 0.7941\n",
      "Epoch 00005: val_auc improved from 0.78905 to 0.78915, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3936 - auc: 0.7940 - val_loss: 0.3973 - val_auc: 0.7892\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3925 - auc: 0.7952\n",
      "Epoch 00006: val_auc improved from 0.78915 to 0.78924, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3925 - auc: 0.7952 - val_loss: 0.3970 - val_auc: 0.7892\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3917 - auc: 0.7964\n",
      "Epoch 00007: val_auc did not improve from 0.78924\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3917 - auc: 0.7964 - val_loss: 0.3968 - val_auc: 0.7892\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3914 - auc: 0.7964Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.78924\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3914 - auc: 0.7964 - val_loss: 0.3970 - val_auc: 0.7892\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 32 : 0.78901\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.5021 - auc: 0.6623\n",
      "Epoch 00001: val_auc improved from -inf to 0.75639, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 135s 229us/sample - loss: 0.5020 - auc: 0.6623 - val_loss: 0.4276 - val_auc: 0.7564\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4158 - auc: 0.7635\n",
      "Epoch 00002: val_auc improved from 0.75639 to 0.78907, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.4158 - auc: 0.7636 - val_loss: 0.3983 - val_auc: 0.7891\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4008 - auc: 0.7837\n",
      "Epoch 00003: val_auc improved from 0.78907 to 0.79660, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.4008 - auc: 0.7837 - val_loss: 0.3917 - val_auc: 0.7966\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3956 - auc: 0.7907\n",
      "Epoch 00004: val_auc improved from 0.79660 to 0.79837, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3956 - auc: 0.7907 - val_loss: 0.3897 - val_auc: 0.7984\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3931 - auc: 0.7940\n",
      "Epoch 00005: val_auc improved from 0.79837 to 0.79866, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3931 - auc: 0.7940 - val_loss: 0.3893 - val_auc: 0.7987\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3919 - auc: 0.7954\n",
      "Epoch 00006: val_auc did not improve from 0.79866\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3919 - auc: 0.7954 - val_loss: 0.3892 - val_auc: 0.7985\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3912 - auc: 0.7964\n",
      "Epoch 00007: val_auc did not improve from 0.79866\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3912 - auc: 0.7964 - val_loss: 0.3894 - val_auc: 0.7979\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3908 - auc: 0.7967Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.79866\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3908 - auc: 0.7967 - val_loss: 0.3894 - val_auc: 0.7979\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 33 : 0.79843\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.5043 - auc: 0.6428\n",
      "Epoch 00001: val_auc improved from -inf to 0.73485, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 135s 229us/sample - loss: 0.5043 - auc: 0.6428 - val_loss: 0.4371 - val_auc: 0.7349\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4212 - auc: 0.7551\n",
      "Epoch 00002: val_auc improved from 0.73485 to 0.77542, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 187us/sample - loss: 0.4212 - auc: 0.7551 - val_loss: 0.4059 - val_auc: 0.7754\n",
      "Epoch 3/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4020 - auc: 0.7819\n",
      "Epoch 00003: val_auc improved from 0.77542 to 0.78535, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.4020 - auc: 0.7819 - val_loss: 0.3984 - val_auc: 0.7853\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3955 - auc: 0.7908\n",
      "Epoch 00004: val_auc improved from 0.78535 to 0.78688, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3955 - auc: 0.7908 - val_loss: 0.3970 - val_auc: 0.7869\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3929 - auc: 0.7942\n",
      "Epoch 00005: val_auc improved from 0.78688 to 0.78704, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3929 - auc: 0.7942 - val_loss: 0.3969 - val_auc: 0.7870\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3918 - auc: 0.7954\n",
      "Epoch 00006: val_auc improved from 0.78704 to 0.78713, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3918 - auc: 0.7954 - val_loss: 0.3969 - val_auc: 0.7871\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3912 - auc: 0.7962\n",
      "Epoch 00007: val_auc did not improve from 0.78713\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3913 - auc: 0.7962 - val_loss: 0.3969 - val_auc: 0.7869\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3908 - auc: 0.7969Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.78713\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3908 - auc: 0.7970 - val_loss: 0.3971 - val_auc: 0.7867\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 34 : 0.78733\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.5015 - auc: 0.6244\n",
      "Epoch 00001: val_auc improved from -inf to 0.71973, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 135s 230us/sample - loss: 0.5015 - auc: 0.6245 - val_loss: 0.4441 - val_auc: 0.7197\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4198 - auc: 0.7599\n",
      "Epoch 00002: val_auc improved from 0.71973 to 0.76973, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.4198 - auc: 0.7599 - val_loss: 0.4116 - val_auc: 0.7697\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4025 - auc: 0.7830\n",
      "Epoch 00003: val_auc improved from 0.76973 to 0.77934, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.4025 - auc: 0.7830 - val_loss: 0.4043 - val_auc: 0.7793\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3970 - auc: 0.7900\n",
      "Epoch 00004: val_auc improved from 0.77934 to 0.78264, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3970 - auc: 0.7900 - val_loss: 0.4016 - val_auc: 0.7826\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3941 - auc: 0.7935\n",
      "Epoch 00005: val_auc improved from 0.78264 to 0.78321, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3941 - auc: 0.7935 - val_loss: 0.4008 - val_auc: 0.7832\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3929 - auc: 0.7946\n",
      "Epoch 00006: val_auc improved from 0.78321 to 0.78326, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3929 - auc: 0.7946 - val_loss: 0.4004 - val_auc: 0.7833\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3920 - auc: 0.7958\n",
      "Epoch 00007: val_auc did not improve from 0.78326\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3919 - auc: 0.7958 - val_loss: 0.4004 - val_auc: 0.7832\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3915 - auc: 0.7962Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.78326\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3915 - auc: 0.7962 - val_loss: 0.4002 - val_auc: 0.7831\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 35 : 0.78321\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.5106 - auc: 0.6380\n",
      "Epoch 00001: val_auc improved from -inf to 0.74223, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 135s 229us/sample - loss: 0.5106 - auc: 0.6380 - val_loss: 0.4385 - val_auc: 0.7422\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4196 - auc: 0.7631\n",
      "Epoch 00002: val_auc improved from 0.74223 to 0.78166, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.4196 - auc: 0.7631 - val_loss: 0.4045 - val_auc: 0.7817\n",
      "Epoch 3/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4021 - auc: 0.7827\n",
      "Epoch 00003: val_auc improved from 0.78166 to 0.78772, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.4021 - auc: 0.7827 - val_loss: 0.3977 - val_auc: 0.7877\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3964 - auc: 0.7897\n",
      "Epoch 00004: val_auc improved from 0.78772 to 0.79044, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3964 - auc: 0.7897 - val_loss: 0.3955 - val_auc: 0.7904\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3937 - auc: 0.7932\n",
      "Epoch 00005: val_auc improved from 0.79044 to 0.79116, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3937 - auc: 0.7931 - val_loss: 0.3947 - val_auc: 0.7912\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3923 - auc: 0.7949\n",
      "Epoch 00006: val_auc did not improve from 0.79116\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3923 - auc: 0.7949 - val_loss: 0.3948 - val_auc: 0.7908\n",
      "Epoch 7/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3916 - auc: 0.7958\n",
      "Epoch 00007: val_auc did not improve from 0.79116\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3916 - auc: 0.7958 - val_loss: 0.3947 - val_auc: 0.7906\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3911 - auc: 0.7965Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.79116\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3911 - auc: 0.7964 - val_loss: 0.3947 - val_auc: 0.7905\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 36 : 0.79113\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.5065 - auc: 0.6710\n",
      "Epoch 00001: val_auc improved from -inf to 0.74658, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 135s 229us/sample - loss: 0.5065 - auc: 0.6711 - val_loss: 0.4322 - val_auc: 0.7466\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4183 - auc: 0.7617\n",
      "Epoch 00002: val_auc improved from 0.74658 to 0.77777, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.4183 - auc: 0.7617 - val_loss: 0.4042 - val_auc: 0.7778\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4021 - auc: 0.7817\n",
      "Epoch 00003: val_auc improved from 0.77777 to 0.78687, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.4022 - auc: 0.7817 - val_loss: 0.3970 - val_auc: 0.7869\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3965 - auc: 0.7897\n",
      "Epoch 00004: val_auc improved from 0.78687 to 0.79015, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3965 - auc: 0.7897 - val_loss: 0.3946 - val_auc: 0.7902\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3936 - auc: 0.7938\n",
      "Epoch 00005: val_auc improved from 0.79015 to 0.79085, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3936 - auc: 0.7938 - val_loss: 0.3938 - val_auc: 0.7908\n",
      "Epoch 6/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3923 - auc: 0.7956\n",
      "Epoch 00006: val_auc improved from 0.79085 to 0.79107, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3923 - auc: 0.7956 - val_loss: 0.3937 - val_auc: 0.7911\n",
      "Epoch 7/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3917 - auc: 0.7960\n",
      "Epoch 00007: val_auc did not improve from 0.79107\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3917 - auc: 0.7960 - val_loss: 0.3937 - val_auc: 0.7908\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3910 - auc: 0.7969Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.79107\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3910 - auc: 0.7969 - val_loss: 0.3938 - val_auc: 0.7906\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 37 : 0.79184\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4967 - auc: 0.6560\n",
      "Epoch 00001: val_auc improved from -inf to 0.75267, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 135s 229us/sample - loss: 0.4967 - auc: 0.6561 - val_loss: 0.4294 - val_auc: 0.7527\n",
      "Epoch 2/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4151 - auc: 0.7665\n",
      "Epoch 00002: val_auc improved from 0.75267 to 0.77955, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.4151 - auc: 0.7665 - val_loss: 0.4049 - val_auc: 0.7795\n",
      "Epoch 3/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4031 - auc: 0.7809\n",
      "Epoch 00003: val_auc improved from 0.77955 to 0.78302, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.4031 - auc: 0.7809 - val_loss: 0.4013 - val_auc: 0.7830\n",
      "Epoch 4/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3943 - auc: 0.7920\n",
      "Epoch 00008: val_auc improved from 0.78583 to 0.78679, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3943 - auc: 0.7919 - val_loss: 0.3977 - val_auc: 0.7868\n",
      "Epoch 9/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3932 - auc: 0.7935\n",
      "Epoch 00009: val_auc improved from 0.78679 to 0.78716, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3932 - auc: 0.7935 - val_loss: 0.3973 - val_auc: 0.7872\n",
      "Epoch 10/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3926 - auc: 0.7944\n",
      "Epoch 00010: val_auc improved from 0.78716 to 0.78778, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3925 - auc: 0.7945 - val_loss: 0.3968 - val_auc: 0.7878\n",
      "Epoch 11/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3920 - auc: 0.7953\n",
      "Epoch 00011: val_auc improved from 0.78778 to 0.78824, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3920 - auc: 0.7953 - val_loss: 0.3963 - val_auc: 0.7882\n",
      "Epoch 12/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3915 - auc: 0.7960\n",
      "Epoch 00012: val_auc improved from 0.78824 to 0.78850, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3914 - auc: 0.7960 - val_loss: 0.3960 - val_auc: 0.7885\n",
      "Epoch 13/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3912 - auc: 0.7965\n",
      "Epoch 00013: val_auc improved from 0.78850 to 0.78890, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3911 - auc: 0.7965 - val_loss: 0.3959 - val_auc: 0.7889\n",
      "Epoch 14/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3908 - auc: 0.7972\n",
      "Epoch 00014: val_auc improved from 0.78890 to 0.78920, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3908 - auc: 0.7971 - val_loss: 0.3956 - val_auc: 0.7892\n",
      "Epoch 15/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3906 - auc: 0.7971Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.78920\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3906 - auc: 0.7970 - val_loss: 0.3957 - val_auc: 0.7891\n",
      "Epoch 00015: early stopping\n",
      "validation AUC fold 38 : 0.78989\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.5026 - auc: 0.6245\n",
      "Epoch 00001: val_auc improved from -inf to 0.73025, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 135s 229us/sample - loss: 0.5026 - auc: 0.6246 - val_loss: 0.4403 - val_auc: 0.7302\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4189 - auc: 0.7617\n",
      "Epoch 00002: val_auc improved from 0.73025 to 0.77341, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.4189 - auc: 0.7617 - val_loss: 0.4081 - val_auc: 0.7734\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4011 - auc: 0.7851\n",
      "Epoch 00003: val_auc improved from 0.77341 to 0.77990, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.4010 - auc: 0.7851 - val_loss: 0.4020 - val_auc: 0.7799\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3958 - auc: 0.7916\n",
      "Epoch 00004: val_auc improved from 0.77990 to 0.78154, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3958 - auc: 0.7916 - val_loss: 0.4004 - val_auc: 0.7815\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3937 - auc: 0.7939\n",
      "Epoch 00005: val_auc improved from 0.78154 to 0.78206, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3937 - auc: 0.7939 - val_loss: 0.4000 - val_auc: 0.7821\n",
      "Epoch 6/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3922 - auc: 0.7956\n",
      "Epoch 00006: val_auc did not improve from 0.78206\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3922 - auc: 0.7956 - val_loss: 0.3999 - val_auc: 0.7820\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3916 - auc: 0.7963\n",
      "Epoch 00007: val_auc did not improve from 0.78206\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3916 - auc: 0.7963 - val_loss: 0.4000 - val_auc: 0.7818\n",
      "Epoch 8/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3911 - auc: 0.7968Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.78206\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3911 - auc: 0.7968 - val_loss: 0.4002 - val_auc: 0.7815\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 39 : 0.78216\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.5044 - auc: 0.6503\n",
      "Epoch 00001: val_auc improved from -inf to 0.73043, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 134s 228us/sample - loss: 0.5044 - auc: 0.6504 - val_loss: 0.4373 - val_auc: 0.7304\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4179 - auc: 0.7607\n",
      "Epoch 00002: val_auc improved from 0.73043 to 0.77384, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.4178 - auc: 0.7607 - val_loss: 0.4069 - val_auc: 0.7738\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4004 - auc: 0.7842\n",
      "Epoch 00003: val_auc improved from 0.77384 to 0.78109, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.4005 - auc: 0.7841 - val_loss: 0.4015 - val_auc: 0.7811\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3952 - auc: 0.7914\n",
      "Epoch 00004: val_auc improved from 0.78109 to 0.78284, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3952 - auc: 0.7914 - val_loss: 0.4003 - val_auc: 0.7828\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3929 - auc: 0.7942\n",
      "Epoch 00005: val_auc improved from 0.78284 to 0.78319, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3929 - auc: 0.7942 - val_loss: 0.4003 - val_auc: 0.7832\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3919 - auc: 0.7955\n",
      "Epoch 00006: val_auc improved from 0.78319 to 0.78339, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3919 - auc: 0.7955 - val_loss: 0.4001 - val_auc: 0.7834\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3912 - auc: 0.7965\n",
      "Epoch 00007: val_auc did not improve from 0.78339\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3912 - auc: 0.7965 - val_loss: 0.4003 - val_auc: 0.7833\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3909 - auc: 0.7967Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.78339\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3909 - auc: 0.7967 - val_loss: 0.4003 - val_auc: 0.7833\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 40 : 0.78297\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.5034 - auc: 0.6261\n",
      "Epoch 00001: val_auc improved from -inf to 0.72038, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 135s 229us/sample - loss: 0.5033 - auc: 0.6262 - val_loss: 0.4426 - val_auc: 0.7204\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4196 - auc: 0.7606\n",
      "Epoch 00002: val_auc improved from 0.72038 to 0.76516, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.4196 - auc: 0.7606 - val_loss: 0.4127 - val_auc: 0.7652\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4039 - auc: 0.7803\n",
      "Epoch 00003: val_auc improved from 0.76516 to 0.77366, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.4039 - auc: 0.7803 - val_loss: 0.4069 - val_auc: 0.7737\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3989 - auc: 0.7866\n",
      "Epoch 00004: val_auc improved from 0.77366 to 0.77734, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3989 - auc: 0.7866 - val_loss: 0.4042 - val_auc: 0.7773\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3959 - auc: 0.7905\n",
      "Epoch 00005: val_auc improved from 0.77734 to 0.77978, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3959 - auc: 0.7905 - val_loss: 0.4025 - val_auc: 0.7798\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3940 - auc: 0.7931\n",
      "Epoch 00006: val_auc improved from 0.77978 to 0.78084, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3940 - auc: 0.7931 - val_loss: 0.4019 - val_auc: 0.7808\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3928 - auc: 0.7946\n",
      "Epoch 00007: val_auc improved from 0.78084 to 0.78148, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3928 - auc: 0.7946 - val_loss: 0.4014 - val_auc: 0.7815\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3921 - auc: 0.7953\n",
      "Epoch 00008: val_auc did not improve from 0.78148\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3921 - auc: 0.7953 - val_loss: 0.4013 - val_auc: 0.7813\n",
      "Epoch 9/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3916 - auc: 0.7962\n",
      "Epoch 00009: val_auc improved from 0.78148 to 0.78158, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 110s 188us/sample - loss: 0.3916 - auc: 0.7962 - val_loss: 0.4012 - val_auc: 0.7816\n",
      "Epoch 10/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3913 - auc: 0.7966Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.78158\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3913 - auc: 0.7966 - val_loss: 0.4013 - val_auc: 0.7815\n",
      "Epoch 00010: early stopping\n",
      "validation AUC fold 41 : 0.78232\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.5059 - auc: 0.6589\n",
      "Epoch 00001: val_auc improved from -inf to 0.71515, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 135s 230us/sample - loss: 0.5058 - auc: 0.6589 - val_loss: 0.4446 - val_auc: 0.7151\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4257 - auc: 0.7478\n",
      "Epoch 00002: val_auc improved from 0.71515 to 0.76620, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.4257 - auc: 0.7478 - val_loss: 0.4132 - val_auc: 0.7662\n",
      "Epoch 3/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4052 - auc: 0.7765\n",
      "Epoch 00003: val_auc improved from 0.76620 to 0.77976, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.4052 - auc: 0.7765 - val_loss: 0.4023 - val_auc: 0.7798\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3975 - auc: 0.7871\n",
      "Epoch 00004: val_auc improved from 0.77976 to 0.78493, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3975 - auc: 0.7871 - val_loss: 0.3987 - val_auc: 0.7849\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3944 - auc: 0.7917\n",
      "Epoch 00005: val_auc improved from 0.78493 to 0.78671, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3943 - auc: 0.7917 - val_loss: 0.3975 - val_auc: 0.7867\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3926 - auc: 0.7943\n",
      "Epoch 00006: val_auc improved from 0.78671 to 0.78681, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3926 - auc: 0.7943 - val_loss: 0.3971 - val_auc: 0.7868\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3917 - auc: 0.7957\n",
      "Epoch 00007: val_auc did not improve from 0.78681\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3917 - auc: 0.7957 - val_loss: 0.3973 - val_auc: 0.7867\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3910 - auc: 0.7964\n",
      "Epoch 00008: val_auc improved from 0.78681 to 0.78699, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3910 - auc: 0.7964 - val_loss: 0.3971 - val_auc: 0.7870\n",
      "Epoch 9/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3908 - auc: 0.7967Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.78699\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3908 - auc: 0.7967 - val_loss: 0.3973 - val_auc: 0.7867\n",
      "Epoch 00009: early stopping\n",
      "validation AUC fold 42 : 0.78712\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4996 - auc: 0.6430\n",
      "Epoch 00001: val_auc improved from -inf to 0.72675, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 135s 230us/sample - loss: 0.4995 - auc: 0.6431 - val_loss: 0.4387 - val_auc: 0.7268\n",
      "Epoch 2/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4197 - auc: 0.7581\n",
      "Epoch 00002: val_auc improved from 0.72675 to 0.78520, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.4197 - auc: 0.7581 - val_loss: 0.4023 - val_auc: 0.7852\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4012 - auc: 0.7841\n",
      "Epoch 00003: val_auc improved from 0.78520 to 0.79392, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.4012 - auc: 0.7841 - val_loss: 0.3941 - val_auc: 0.7939\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3965 - auc: 0.7899\n",
      "Epoch 00004: val_auc improved from 0.79392 to 0.79599, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3965 - auc: 0.7899 - val_loss: 0.3922 - val_auc: 0.7960\n",
      "Epoch 5/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3944 - auc: 0.7925\n",
      "Epoch 00005: val_auc did not improve from 0.79599\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3944 - auc: 0.7925 - val_loss: 0.3919 - val_auc: 0.7958\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3933 - auc: 0.7941\n",
      "Epoch 00006: val_auc improved from 0.79599 to 0.79600, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3933 - auc: 0.7941 - val_loss: 0.3918 - val_auc: 0.7960\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3925 - auc: 0.7950\n",
      "Epoch 00007: val_auc did not improve from 0.79600\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3925 - auc: 0.7951 - val_loss: 0.3920 - val_auc: 0.7954\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3922 - auc: 0.7953Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.79600\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3922 - auc: 0.7953 - val_loss: 0.3921 - val_auc: 0.7953\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 43 : 0.79482\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.5055 - auc: 0.6607\n",
      "Epoch 00001: val_auc improved from -inf to 0.72603, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 135s 230us/sample - loss: 0.5055 - auc: 0.6607 - val_loss: 0.4422 - val_auc: 0.7260\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4256 - auc: 0.7486\n",
      "Epoch 00002: val_auc improved from 0.72603 to 0.77039, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.4256 - auc: 0.7486 - val_loss: 0.4102 - val_auc: 0.7704\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4053 - auc: 0.7760\n",
      "Epoch 00003: val_auc improved from 0.77039 to 0.78073, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.4053 - auc: 0.7760 - val_loss: 0.4015 - val_auc: 0.7807\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3977 - auc: 0.7867\n",
      "Epoch 00004: val_auc improved from 0.78073 to 0.78573, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3977 - auc: 0.7867 - val_loss: 0.3986 - val_auc: 0.7857\n",
      "Epoch 5/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3943 - auc: 0.7919\n",
      "Epoch 00005: val_auc improved from 0.78573 to 0.78684, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3943 - auc: 0.7919 - val_loss: 0.3976 - val_auc: 0.7868\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3924 - auc: 0.7944\n",
      "Epoch 00006: val_auc did not improve from 0.78684\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3924 - auc: 0.7944 - val_loss: 0.3975 - val_auc: 0.7868\n",
      "Epoch 7/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3914 - auc: 0.7959\n",
      "Epoch 00007: val_auc improved from 0.78684 to 0.78714, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3914 - auc: 0.7959 - val_loss: 0.3972 - val_auc: 0.7871\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3911 - auc: 0.7964\n",
      "Epoch 00008: val_auc did not improve from 0.78714\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3910 - auc: 0.7964 - val_loss: 0.3973 - val_auc: 0.7871\n",
      "Epoch 9/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3908 - auc: 0.7965Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00009: val_auc did not improve from 0.78714\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3908 - auc: 0.7965 - val_loss: 0.3973 - val_auc: 0.7870\n",
      "Epoch 00009: early stopping\n",
      "validation AUC fold 44 : 0.78726\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.5049 - auc: 0.6050\n",
      "Epoch 00001: val_auc improved from -inf to 0.72295, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 135s 230us/sample - loss: 0.5049 - auc: 0.6051 - val_loss: 0.4445 - val_auc: 0.7229\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4218 - auc: 0.7571\n",
      "Epoch 00002: val_auc improved from 0.72295 to 0.77448, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.4218 - auc: 0.7572 - val_loss: 0.4072 - val_auc: 0.7745\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4020 - auc: 0.7836\n",
      "Epoch 00003: val_auc improved from 0.77448 to 0.78162, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.4020 - auc: 0.7836 - val_loss: 0.4010 - val_auc: 0.7816\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3966 - auc: 0.7903\n",
      "Epoch 00004: val_auc improved from 0.78162 to 0.78318, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3966 - auc: 0.7903 - val_loss: 0.3994 - val_auc: 0.7832\n",
      "Epoch 5/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3940 - auc: 0.7934\n",
      "Epoch 00005: val_auc improved from 0.78318 to 0.78392, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3940 - auc: 0.7934 - val_loss: 0.3989 - val_auc: 0.7839\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3926 - auc: 0.7950\n",
      "Epoch 00006: val_auc did not improve from 0.78392\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3927 - auc: 0.7950 - val_loss: 0.3989 - val_auc: 0.7837\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3921 - auc: 0.7956\n",
      "Epoch 00007: val_auc did not improve from 0.78392\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3921 - auc: 0.7956 - val_loss: 0.3990 - val_auc: 0.7833\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3915 - auc: 0.7963Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.78392\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3915 - auc: 0.7963 - val_loss: 0.3991 - val_auc: 0.7831\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 45 : 0.78442\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.5048 - auc: 0.6125\n",
      "Epoch 00001: val_auc improved from -inf to 0.71682, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 135s 230us/sample - loss: 0.5047 - auc: 0.6125 - val_loss: 0.4449 - val_auc: 0.7168\n",
      "Epoch 2/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4207 - auc: 0.7576\n",
      "Epoch 00002: val_auc improved from 0.71682 to 0.77090, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.4207 - auc: 0.7577 - val_loss: 0.4100 - val_auc: 0.7709\n",
      "Epoch 3/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4011 - auc: 0.7844\n",
      "Epoch 00003: val_auc improved from 0.77090 to 0.77965, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.4010 - auc: 0.7844 - val_loss: 0.4031 - val_auc: 0.7796\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3956 - auc: 0.7913\n",
      "Epoch 00004: val_auc improved from 0.77965 to 0.78186, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3956 - auc: 0.7913 - val_loss: 0.4012 - val_auc: 0.7819\n",
      "Epoch 5/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3934 - auc: 0.7941\n",
      "Epoch 00005: val_auc improved from 0.78186 to 0.78225, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3934 - auc: 0.7941 - val_loss: 0.4007 - val_auc: 0.7823\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3923 - auc: 0.7955\n",
      "Epoch 00006: val_auc did not improve from 0.78225\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3922 - auc: 0.7955 - val_loss: 0.4007 - val_auc: 0.7820\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3916 - auc: 0.7962\n",
      "Epoch 00007: val_auc improved from 0.78225 to 0.78230, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3916 - auc: 0.7963 - val_loss: 0.4004 - val_auc: 0.7823\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3912 - auc: 0.7965Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.78230\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3912 - auc: 0.7965 - val_loss: 0.4007 - val_auc: 0.7818\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 46 : 0.78326\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.5050 - auc: 0.6144\n",
      "Epoch 00001: val_auc improved from -inf to 0.72471, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 135s 230us/sample - loss: 0.5049 - auc: 0.6144 - val_loss: 0.4457 - val_auc: 0.7247\n",
      "Epoch 2/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.4218 - auc: 0.7577\n",
      "Epoch 00002: val_auc improved from 0.72471 to 0.77345, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.4218 - auc: 0.7577 - val_loss: 0.4103 - val_auc: 0.7735\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4015 - auc: 0.7844\n",
      "Epoch 00003: val_auc improved from 0.77345 to 0.78114, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.4015 - auc: 0.7844 - val_loss: 0.4037 - val_auc: 0.7811\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3958 - auc: 0.7916\n",
      "Epoch 00004: val_auc improved from 0.78114 to 0.78265, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3958 - auc: 0.7916 - val_loss: 0.4021 - val_auc: 0.7826\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3936 - auc: 0.7939\n",
      "Epoch 00005: val_auc did not improve from 0.78265\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3936 - auc: 0.7940 - val_loss: 0.4019 - val_auc: 0.7826\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3924 - auc: 0.7954\n",
      "Epoch 00006: val_auc did not improve from 0.78265\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3924 - auc: 0.7954 - val_loss: 0.4016 - val_auc: 0.7825\n",
      "Epoch 7/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3916 - auc: 0.7961\n",
      "Epoch 00007: val_auc did not improve from 0.78265\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3916 - auc: 0.7960 - val_loss: 0.4018 - val_auc: 0.7818\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3911 - auc: 0.7967Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.78265\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3911 - auc: 0.7967 - val_loss: 0.4019 - val_auc: 0.7817\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 47 : 0.78245\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.5004 - auc: 0.6455\n",
      "Epoch 00001: val_auc improved from -inf to 0.72367, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 135s 230us/sample - loss: 0.5004 - auc: 0.6455 - val_loss: 0.4381 - val_auc: 0.7237\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4195 - auc: 0.7566\n",
      "Epoch 00002: val_auc improved from 0.72367 to 0.76544, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.4195 - auc: 0.7566 - val_loss: 0.4108 - val_auc: 0.7654\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4020 - auc: 0.7817\n",
      "Epoch 00003: val_auc improved from 0.76544 to 0.77418, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.4020 - auc: 0.7817 - val_loss: 0.4049 - val_auc: 0.7742\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3962 - auc: 0.7899\n",
      "Epoch 00004: val_auc improved from 0.77418 to 0.77710, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3962 - auc: 0.7899 - val_loss: 0.4032 - val_auc: 0.7771\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3934 - auc: 0.7936\n",
      "Epoch 00005: val_auc improved from 0.77710 to 0.77790, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3934 - auc: 0.7936 - val_loss: 0.4027 - val_auc: 0.7779\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3918 - auc: 0.7958\n",
      "Epoch 00006: val_auc did not improve from 0.77790\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3918 - auc: 0.7958 - val_loss: 0.4028 - val_auc: 0.7777\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3913 - auc: 0.7963\n",
      "Epoch 00007: val_auc did not improve from 0.77790\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3912 - auc: 0.7963 - val_loss: 0.4028 - val_auc: 0.7776\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3907 - auc: 0.7970Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.77790\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3907 - auc: 0.7970 - val_loss: 0.4030 - val_auc: 0.7774\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 48 : 0.77773\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4947 - auc: 0.6596\n",
      "Epoch 00001: val_auc improved from -inf to 0.75793, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 135s 229us/sample - loss: 0.4947 - auc: 0.6596 - val_loss: 0.4272 - val_auc: 0.7579\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4145 - auc: 0.7665\n",
      "Epoch 00002: val_auc improved from 0.75793 to 0.78771, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.4145 - auc: 0.7665 - val_loss: 0.3997 - val_auc: 0.7877\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4009 - auc: 0.7838\n",
      "Epoch 00003: val_auc improved from 0.78771 to 0.79303, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.4009 - auc: 0.7838 - val_loss: 0.3936 - val_auc: 0.7930\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3959 - auc: 0.7901\n",
      "Epoch 00004: val_auc improved from 0.79303 to 0.79476, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3959 - auc: 0.7901 - val_loss: 0.3918 - val_auc: 0.7948\n",
      "Epoch 5/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3934 - auc: 0.7933\n",
      "Epoch 00005: val_auc did not improve from 0.79476\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3934 - auc: 0.7933 - val_loss: 0.3917 - val_auc: 0.7945\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3920 - auc: 0.7953\n",
      "Epoch 00006: val_auc did not improve from 0.79476\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3920 - auc: 0.7953 - val_loss: 0.3920 - val_auc: 0.7938\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3912 - auc: 0.7962\n",
      "Epoch 00007: val_auc did not improve from 0.79476\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3912 - auc: 0.7962 - val_loss: 0.3923 - val_auc: 0.7934\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3908 - auc: 0.7969Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00008: val_auc did not improve from 0.79476\n",
      "588000/588000 [==============================] - 111s 188us/sample - loss: 0.3908 - auc: 0.7968 - val_loss: 0.3924 - val_auc: 0.7931\n",
      "Epoch 00008: early stopping\n",
      "validation AUC fold 49 : 0.79442\n",
      "Train on 588000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.5074 - auc: 0.6708\n",
      "Epoch 00001: val_auc improved from -inf to 0.73084, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 135s 229us/sample - loss: 0.5073 - auc: 0.6708 - val_loss: 0.4378 - val_auc: 0.7308\n",
      "Epoch 2/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4189 - auc: 0.7592\n",
      "Epoch 00002: val_auc improved from 0.73084 to 0.77658, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.4189 - auc: 0.7592 - val_loss: 0.4068 - val_auc: 0.7766\n",
      "Epoch 3/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.4019 - auc: 0.7813\n",
      "Epoch 00003: val_auc improved from 0.77658 to 0.78765, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.4019 - auc: 0.7813 - val_loss: 0.3988 - val_auc: 0.7877\n",
      "Epoch 4/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3965 - auc: 0.7887\n",
      "Epoch 00004: val_auc improved from 0.78765 to 0.79171, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3965 - auc: 0.7887 - val_loss: 0.3962 - val_auc: 0.7917\n",
      "Epoch 5/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3941 - auc: 0.7922\n",
      "Epoch 00005: val_auc improved from 0.79171 to 0.79265, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3941 - auc: 0.7923 - val_loss: 0.3952 - val_auc: 0.7927\n",
      "Epoch 6/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3928 - auc: 0.7940\n",
      "Epoch 00006: val_auc did not improve from 0.79265\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3928 - auc: 0.7940 - val_loss: 0.3950 - val_auc: 0.7926\n",
      "Epoch 7/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3920 - auc: 0.7950\n",
      "Epoch 00007: val_auc improved from 0.79265 to 0.79296, saving model to nn_model.w8\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3921 - auc: 0.7950 - val_loss: 0.3947 - val_auc: 0.7930\n",
      "Epoch 8/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3917 - auc: 0.7955\n",
      "Epoch 00008: val_auc did not improve from 0.79296\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3917 - auc: 0.7955 - val_loss: 0.3948 - val_auc: 0.7928\n",
      "Epoch 9/15\n",
      "587520/588000 [============================>.] - ETA: 0s - loss: 0.3911 - auc: 0.7964\n",
      "Epoch 00009: val_auc did not improve from 0.79296\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3911 - auc: 0.7964 - val_loss: 0.3949 - val_auc: 0.7924\n",
      "Epoch 10/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3908 - auc: 0.7967\n",
      "Epoch 00010: val_auc did not improve from 0.79296\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3908 - auc: 0.7967 - val_loss: 0.3949 - val_auc: 0.7922\n",
      "Epoch 11/15\n",
      "587776/588000 [============================>.] - ETA: 0s - loss: 0.3907 - auc: 0.7970Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00011: val_auc did not improve from 0.79296\n",
      "588000/588000 [==============================] - 111s 189us/sample - loss: 0.3907 - auc: 0.7970 - val_loss: 0.3952 - val_auc: 0.7917\n",
      "Epoch 00011: early stopping\n",
      "validation AUC fold 50 : 0.79235\n"
     ]
    }
   ],
   "source": [
    "oof_pred_deepfm = np.zeros((len(train), ))\n",
    "y_pred_deepfm = np.zeros((len(test),))\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_Splits, shuffle=True, random_state=SEED)\n",
    "for fold, (tr_ind, val_ind) in enumerate(skf.split(train, train[target])):\n",
    "    X_train, X_val = train[sparse_features+missing_indicator_cols].iloc[tr_ind], train[sparse_features+missing_indicator_cols].iloc[val_ind]\n",
    "    y_train, y_val = train[target].iloc[tr_ind], train[target].iloc[val_ind]\n",
    "    train_model_input = {name:X_train[name] for name in feature_names}\n",
    "    val_model_input = {name:X_val[name] for name in feature_names}\n",
    "    test_model_input = {name:test[name] for name in feature_names}\n",
    "    \n",
    "    model = DeepFM(linear_feature_columns, dnn_feature_columns, dnn_hidden_units=(256, 256), dnn_dropout=0.05, dnn_use_bn=True, task='binary')\n",
    "    model.compile(ranger, \"binary_crossentropy\", metrics=[auc], )\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor='val_auc',min_delta=0.001, patience=4, verbose=Verbose, mode='max', baseline=None, restore_best_weights=True)\n",
    "    sb = callbacks.ModelCheckpoint(monitor='val_auc',filepath='nn_model.w8', save_weights_only=True, mode='max', save_best_only=True, verbose=Verbose)\n",
    "    clr = CyclicLR(base_lr=0.00001 / 100, max_lr = 0.0001, \n",
    "                       step_size= int(1.0*(test.shape[0])/1024) , mode='exp_range',\n",
    "                       gamma=1., scale_fn=None, scale_mode='cycle')\n",
    "    \n",
    "    history = model.fit(train_model_input, y_train,\n",
    "                        validation_data=(val_model_input, y_val),\n",
    "                        batch_size=256, epochs=Epochs, verbose=Verbose,\n",
    "                        callbacks=[es, sb, clr],)\n",
    "    \n",
    "    model.load_weights('nn_model.w8')\n",
    "    \n",
    "    val_pred = model.predict(val_model_input, batch_size=256)\n",
    "    print(f\"validation AUC fold {fold+1} : {round(roc_auc_score(y_val, val_pred), 5)}\")\n",
    "    oof_pred_deepfm[val_ind] = val_pred.ravel()\n",
    "    y_pred_deepfm += model.predict(test_model_input, batch_size=256).ravel() / (N_Splits)\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF AUC : 0.78769\n"
     ]
    }
   ],
   "source": [
    "print(f\"OOF AUC : {round(roc_auc_score(train.target.values, oof_pred_deepfm), 5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved!\n"
     ]
    }
   ],
   "source": [
    "test_idx = test.id.values\n",
    "submission = pd.DataFrame.from_dict({\n",
    "    'id': test_idx,\n",
    "    'target': y_pred_deepfm\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Submission file saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('oof_pred_deepfm.npy',oof_pred_deepfm)\n",
    "np.save('y_pred_deepfm.npy',    y_pred_deepfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
