{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "X = pd.read_csv(\"train.csv\")\n",
    "Xt = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Separating target and ids\n",
    "y = X.target.values\n",
    "id_train = X.id\n",
    "id_test = Xt.id\n",
    "\n",
    "X.drop(['id', 'target'], axis=1, inplace=True)\n",
    "Xt.drop(['id'], axis=1, inplace=True)\n",
    "\n",
    "# Classifying variables in binary, high and low cardinality nominal, ordinal and dates\n",
    "binary_vars = [c for c in X.columns if 'bin_' in c]\n",
    "\n",
    "nominal_vars = [c for c in X.columns if 'nom_' in c]\n",
    "high_cardinality = [c for c in nominal_vars if len(X[c].unique()) > 16]\n",
    "low_cardinality = [c for c in nominal_vars if len(X[c].unique()) <= 16]\n",
    "\n",
    "ordinal_vars = [c for c in X.columns if 'ord_' in c]\n",
    "\n",
    "time_vars = ['day', 'month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some feature engineering\n",
    "X['ord_5_1'] = X['ord_5'].apply(lambda x: x[0] if type(x) == str else np.nan)\n",
    "X['ord_5_2'] = X['ord_5'].apply(lambda x: x[1] if type(x) == str else np.nan)\n",
    "Xt['ord_5_1'] = Xt['ord_5'].apply(lambda x: x[0] if type(x) == str else np.nan)\n",
    "Xt['ord_5_2'] = Xt['ord_5'].apply(lambda x: x[1] if type(x) == str else np.nan)\n",
    "\n",
    "ordinal_vars += ['ord_5_1', 'ord_5_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting ordinal labels into ordered values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinals = {\n",
    "    'ord_1' : {\n",
    "        'Novice' : 0,\n",
    "        'Contributor' : 1,\n",
    "        'Expert' : 2,\n",
    "        'Master' : 3,\n",
    "        'Grandmaster' : 4\n",
    "    },\n",
    "    'ord_2' : {\n",
    "        'Freezing' : 0,\n",
    "        'Cold' : 1,\n",
    "        'Warm' : 2,\n",
    "        'Hot' : 3,\n",
    "        'Boiling Hot' : 4,\n",
    "        'Lava Hot' : 5\n",
    "    }\n",
    "}\n",
    "\n",
    "def return_order(X, Xt, var_name):\n",
    "    mode = X[var_name].mode()[0]\n",
    "    # sort value with both data set\n",
    "    el = sorted(set(X[var_name].fillna(mode).unique())|set(Xt[var_name].fillna(mode).unique()))\n",
    "    # create code dictionary\n",
    "    return {v:e for e, v in enumerate(el)}\n",
    "\n",
    "for mapped_var in ordinal_vars:\n",
    "    if mapped_var not in ordinals: # if not coded explicitly\n",
    "        mapped_values = return_order(X, Xt, mapped_var)\n",
    "        X[mapped_var + '_num'] = X[mapped_var].replace(mapped_values)\n",
    "        Xt[mapped_var + '_num'] = Xt[mapped_var].replace(mapped_values)\n",
    "    else:\n",
    "        X[mapped_var + '_num'] = X[mapped_var].replace(ordinals[mapped_var])\n",
    "        Xt[mapped_var + '_num'] = Xt[mapped_var].replace(ordinals[mapped_var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming all the labels of all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = [LabelEncoder() for _ in range(X.shape[1])]\n",
    "\n",
    "for col, column in enumerate(X.columns):\n",
    "    unique_values = pd.Series(X[column].append(Xt[column]).unique())\n",
    "    unique_values = unique_values[unique_values.notnull()]\n",
    "    label_encoders[col].fit(unique_values)\n",
    "    X.loc[X[column].notnull(), column] = label_encoders[col].transform(X.loc[X[column].notnull(), column])\n",
    "    Xt.loc[Xt[column].notnull(), column] = label_encoders[col].transform(Xt.loc[Xt[column].notnull(), column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with any residual missing value\n",
    "X = X.fillna(-1)\n",
    "Xt = Xt.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enconding frequencies instead of labels (so we have some numeric variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_encoding(column, df, df_test=None):\n",
    "    frequencies = df[column].value_counts().reset_index()\n",
    "    df_values = df[[column]].merge(frequencies, how='left', \n",
    "                                   left_on=column, right_on='index').iloc[:,-1].values\n",
    "    if df_test is not None:\n",
    "        df_test_values = df_test[[column]].merge(frequencies, how='left', \n",
    "                                                 left_on=column, right_on='index').fillna(1).iloc[:,-1].values\n",
    "    else:\n",
    "        df_test_values = None\n",
    "    return df_values, df_test_values\n",
    "\n",
    "for column in X.columns:\n",
    "    train_values, test_values = frequency_encoding(column, X, Xt)\n",
    "    X[column+'_counts'] = train_values\n",
    "    Xt[column+'_counts'] = test_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target encoding of selected variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['fold_column'] = 0\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, random_state=137)\n",
    "\n",
    "import category_encoders as cat_encs\n",
    "\n",
    "cat_feat_to_encode = binary_vars + ordinal_vars + nominal_vars + time_vars\n",
    "smoothing = 0.3 #smoothing effect to balance categorical average vs prior. Higher value means stronger regularization. The value must be strictly bigger than 0.\n",
    "\n",
    "# to store oof prediction\n",
    "enc_x = np.zeros(X[cat_feat_to_encode].shape)\n",
    "\n",
    "for i, (tr_idx, oof_idx) in enumerate(kf.split(X, y)):\n",
    "    #For the case of categorical target: \n",
    "    # features are replaced with a blend of posterior probability of the target given particular categorical value\n",
    "    # and the prior probability of the target over all the training data.\n",
    "\n",
    "    #For the case of continuous target: \n",
    "    # features are replaced with a blend of the expected value of the target given particular categorical value \n",
    "    # and the expected value of the target over all the training data.\n",
    "    encoder = cat_encs.TargetEncoder(cols=cat_feat_to_encode, smoothing=smoothing)\n",
    "    \n",
    "    # k fold\n",
    "    X.loc[oof_idx, 'fold_column'] = i\n",
    "    \n",
    "    # fit the fold\n",
    "    encoder.fit(X[cat_feat_to_encode].iloc[tr_idx], y[tr_idx])\n",
    "    # transform oof\n",
    "    enc_x[oof_idx, :] = encoder.transform(X[cat_feat_to_encode].iloc[oof_idx], y[oof_idx])\n",
    "\n",
    "# fit the whole dataset\n",
    "encoder.fit(X[cat_feat_to_encode], y)\n",
    "# transofrm the whole test dataset\n",
    "enc_xt = encoder.transform(Xt[cat_feat_to_encode]).values\n",
    "\n",
    "for idx, new_var in enumerate(cat_feat_to_encode):\n",
    "    new_var = new_var + '_enc' #create new var with encoder transformed value\n",
    "    X[new_var] = enc_x[:,idx]\n",
    "    Xt[new_var] = enc_xt[:, idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4']\n",
      "['ord_0', 'ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5', 'ord_5_1', 'ord_5_2']\n",
      "['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4', 'nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9']\n",
      "['day', 'month']\n"
     ]
    }
   ],
   "source": [
    "print(binary_vars)\n",
    "print(ordinal_vars)\n",
    "print(nominal_vars)\n",
    "print(time_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(np.float32)\n",
    "Xt = Xt.astype(np.float32)\n",
    "\n",
    "# Defining categorical variables\n",
    "cat_features = nominal_vars + ordinal_vars\n",
    "\n",
    "# Setting categorical variables to int64\n",
    "X[cat_features] = X[cat_features].astype(np.int64)\n",
    "Xt[cat_features] = Xt[cat_features].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['target'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('X_train_te.csv', index=False)\n",
    "Xt.to_csv('X_test_te.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
